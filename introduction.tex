\begin{note}
%\label{remark:}
In this book, \term{predicate language} is used as a synonym of \term{first-order language}, and \term{constructive logic} is used as a synonym of \term{intuitionistic logic}.
\end{note}

\section{Introduction. What Is Logic, Really?}

What is logic?
[See also Factasia Logic\footnote{\url{http://www.rbjones.com/rbjpub/logic/}} by Roger Bishop Jones\footnote{\url{http://www.rbjones.com/}}.]
In a sense, logic represents the most general \emph{means of reasoning} used by people and computers.

Why are means of reasoning important?
Because any body of data may contain not only facts visible directly.
For example, assume the following data: the date of birth of some person \(X\) is January 1, 2000,
and yesterday, September 14, 2010 some person \(Y\) killed some person \(Z\).
Then, most likely, \(X\) did not kill \(Z\).
This conclusion is not represented in our data directly, but can be derived from it by using some means of reasoning---\term{axioms} (``background knowledge'') and \term{rules of inference}.
For example, one may use the following statement as an axiom: ``Most likely, a person of age 10 can't kill anybody''.

There may be means of reasoning of different levels of generality, i.e., of different ranges of applicability.
The above ``killer axiom'' represents the lowest level---it is a very specific statement.
But one can use laws of physics to derive conclusions from one's data.
Theories of physics, chemistry, biology, etc., represent a more general level of means of reasoning.
But can there be means of reasoning applicable in almost every situation?
This---the most general---level of means of reasoning is usually regarded as \term{logic}.

But is logic absolute (i.e., unique, predestined) or relative (i.e., there is more than one kind of logic)?
In modern times, an absolutist position is somewhat inconvenient---you must defend your ``absolute'' concept of logic against heretics and dissidents, but very little can be done to exterminate these people.
They may freely publish their concepts on the internet~\ldots~.

So let us better adopt the relativist position, and define logic as \emph{any common framework for building theories}.
For example, the so-called absolute geometry can be viewed as a common logic for both the Euclidean and non-Euclidean geometry.
Group theory\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/HistTopics/Development\_group\_theory.html}} serves as a common logic for theories investigating mathematical structures that are subtypes of groups.
And, if you decide to rebuild all mathematical theories on your favorite set theory, then you can view set theory as your logic.

Can there be a common logic for the entire mathematics?
To avoid the absolutist approach, let us appreciate all the existing concepts of mathematics---classical (traditional), constructivist (intuitionist), New Foundations\footnote{\url{http://math.boisestate.edu/~holmes/holmes/nf.html}} etc.
Of course, enthusiasts of each of these concepts must propose some specific common framework for building mathematical theories, i.e., some specific kind of logic.
And they do.

Can set theory (for example, the most popular version of it---Zermelo--Fraenkel's set theory\footnote{\url{http://www.ltn.lv/~podnieks/gt2.html\#s23}}) be viewed as a common logic for the classical (traditional) mathematics?
You may think so, if you do not wish to distinguish between the first-order notion of natural numbers (i.e., discrete mathematics) and the second order notion (i.e., ``continuous'' mathematics based on set theory or a subset of it).
Or, if you do not wish to investigate in parallel the classical and the constructivist (intuitionist) versions of some theories.

\subsection{Total Formalization is Possible!}
\begin{itemize}
    \item Gottlob Frege\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Frege.html}} (1848--1925)
    \item Charles S.\ Peirce\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Peirce\_Charles.html}} (1839--1914)
    \item Bertrand Russell\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Russell.html}} (1872--1970)
    \item David Hilbert\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Hilbert.html}} (1862--1943)
\end{itemize}

How far can we proceed with the mathematical rigor---with the axiomatization of some theory?
Complete elimination of intuition, i.e., full reduction of all proofs to a list of axioms and rules of inference, is this really possible?
The work by Gottlob Frege, Charles S.\ Peirce, Bertrand Russell, David Hilbert, and their colleagues showed how this can be achieved even with the most complicated mathematical theories.
All mathematical theories were indeed reduced to systems of axioms and rules of inference without any admixture of sophisticated human skills, intuitions etc.
Today, the logical techniques developed by these brilliant people allow ultimate axiomatization of any theory that is based on a stable, self-consistent system of principles (i.e., of any mathematical theory).

What do they look like---such ``100\% rigorous'' theories?
They are called \term{formal theories} (formal systems, or deductive systems) emphasizing that no step of reasoning can be done without a reference to an exactly formulated list of axioms and rules of inference.
Even the most ``self-evident'' logical principles (like, ``if \(A\) implies \(B\), and \(B\) implies \(C\), then \(A\) implies \(C\)'') must be either formulated in the list of axioms and rules explicitly, or derived from it.

What is, in fact, a (mathematical) theory?
It is an \term{``engine'' generating theorems}.
Then, a formal theory must be an ``engine'' generating theorems without involving of human skills, intuitions etc., i.e., by means of a computer program.

The first distinctive feature of a formal theory is a \term{precisely defined (``formal'') language} used to express its \term{propositions}.
``Precisely defined'' means here that there is an algorithm allowing to determine, is a given character string a correct proposition, or not.

The second distinctive feature of a formal theory is a precisely defined (``formal'') notion of \term{proof}.
Each proof proves some proposition, that is called (after being proved) a \term{theorem}.
Thus, theorems are a subset of propositions.

It may seem surprising to a mathematician, but the most general exact definition of the ``formal proof'' involves neither axioms, nor inference rules.
Neither ``self-evident'' axioms, nor ``plausible'' rules of inference are distinctive features of the ``formality''.
Strictly speaking, ``self-evident'' is synonymous to ``accepted without argumentation''.
Hence, axioms and/or rules of inference may be ``good, or bad'', ``true, or false'', and so may be the theorems obtained by means of them.
The only definitely verifiable thing is here the fact that some theorem has been, indeed, \term{proved} from a fixed set of axioms by means of a fixed set of inference rules.

Thus, the second distinctive feature of ``formality'' is the possibility to \emph{verify the correctness of proofs} mechanically, i.e., without involving of human skills, intuitions etc.
This can be best formulated by using the (since 1936---precisely defined) notion of algorithm (a ``mechanically applicable computation procedure'', a computer program).

\emph{A theory \(T\) is called a formal theory, if and only if there is an algorithm allowing to verify, is a given text a correct proof via principles of \(T\), or not.}
If somebody is going to publish a ``mathematical text'' calling it ``proof of a theorem in theory \(T\)'', then we must be able to verify it mechanically whether the text in question is really a correct proof according to the standards of proving accepted in theory \(T\).
Thus, in a formal theory, the standards of reasoning should be defined precisely enough to enable verification of proofs by means of a computer program.
(Note that we are discussing here \term{verification of ready proofs}, and not the much more difficult problem---is some proposition provable in \(T\) or not, see Exercise 1.1.5 below and the text after it.)

Axioms and inference rules represent only one (the most popular!) of the possible techniques of formalization.

As an unpractical example of a formal theory let us consider the \emph{game of chess}, let us call this ``theory'' \CHESS.
Let's define as propositions of \CHESS\ all the possible positions---i.e., allocations of some of the pieces (kings included) on a chessboard---plus the flag: ``white to move'' or ``black to move''.
Thus, the set of all possible positions is the language of \CHESS.
The only axiom of \CHESS\ is the initial position, and the rules of inference---the rules of the game.
The rules allow passing from some propositions of \CHESS\ to some other ones.
Starting with the axiom and iterating moves allowed by the rules we obtain theorems of \CHESS.
Thus, theorems of \CHESS\ are defined as all the possible positions (i.e., propositions of \CHESS) that can be obtained from the initial position (the axiom of \CHESS) by moving pieces according to the rules of the game (i.e., by ``proving'' via the inference rules of \CHESS).

\begin{exercise}
Could you provide an unprovable proposition of \CHESS?
\end{exercise}

Why is \CHESS\ called a formal theory? When somebody offers a ``mathematical text'' P as a proof of a theorem A in \CHESS, this means that P is a record of some chess-game stopped in the position A.
Checking the correctness of such ``proofs'' is a boring, but an easy task.
The rules of the game are formulated precisely enough---we could write a computer program that will execute this task.

\begin{exercise}
Try estimating the size of this program in some programming language.
\end{exercise}

Our second example of a formal theory is only a bit more serious.
It was proposed by Paul Lorenzen\footnote{\url{http://en.wikipedia.org/wiki/Paul\_Lorenzen}}, let us call this theory \(L\).
Propositions of \(L\) are all the possible ``words'' made of letters \(a, b\), for example: \(a, b, aa, aba, abaab\).
Thus, the set of all these ``words'' is the language of \(L\).
The only axiom of \(L\) is the word \(a\), and \(L\) has two rules of inference: \derive{X}{Xb}, and \derive{X}{aXa}.
This means that (in \(L\)) from a proposition \(X\) we can infer immediately the propositions \(Xb\) and \(aXa\).
For example, the proposition \(aababb\) is a theorem of \(L\):
\[
a \underset{\text{rule1}}{\vdash} ab \underset{\text{rule2}}{\vdash} aaba \underset{\text{rule1}}{\vdash} aabab \underset{rule1}{\vdash} aababb
\]
This fact is expressed usually as \derive{L}{aababb} ( ``\(L\) proves \(aababb\)'', \(\vdash\) being a ``fallen T'').

\begin{exercise}
(a) Verify that \(L\) is a formal theory.
(Hint: describe an algorithm allowing to determine, is a sequence of propositions of \(L\) a correct proof, or not.)
(b) (P.~Lorenzen) Verify the following property of theorems in \(L\): for any \(X\), if \derive{L}{X}, then \derive{L}{aaX}.
\end{exercise}

One of the most important properties of formal theories is given in the following:

\begin{exercise}
Show that the set of all theorems of a formal theory is effectively enumerable, i.e., show that, for any formal theory \(T\), a computer program \(P_T\) can be written that prints out on an (endless) paper tape all theorems of this theory (and nothing else).
(Hint: we will call \(T\) a formal theory if and only if we can present an algorithm for checking texts as correct proofs via principles of reasoning of \(T\).
Thus, assume you have four functions: \texttt{GenerateFirstText()}---returns \texttt{\textit{Text}}, \texttt{GenerateNextText()}---returns \texttt{\textit{Text}}, \texttt{IsCorrectProof(Text)}---returns \texttt{true} or \texttt{false}, \texttt{ExtractTheorem(\textit{Text})}---returns \texttt{Text}, you must implement the functions \texttt{GenerateFirstTheorem()}---returns \texttt{\textit{Text}}, \texttt{GenerateNextTheorem()}---returns \texttt{\textit{Text}}).
Text.)

Unfortunately, \emph{such programs cannot solve the problem that the mathematicians are mainly interested in: is a given proposition \(A\) provable in \(T\) or not?}
When, running the program \(P_T\) on a computer, we see our proposition \(A\) printed out, this means that \(A\) is provable in \(T\).
Still, in general, until that moment we cannot know in advance whether \(A\) will be printed out some time later or it will not be printed at all.
\end{exercise}

\begin{note}
According to the official terminology, effectively enumerable sets are called ``recursively enumerable sets'', in some texts---also ``listable sets''.
\end{note}

\begin{exercise}\label{Lsolvable}
    \begin{inparaenum}[(a)]
        \item Describe an algorithm determining whether a proposition of \(L\) is a theorem or not.
        \item Could you imagine such an algorithm for the theory \CHESS?
        Of course, you can, yet \ldots
        Thus you see that even, having a relatively simple algorithm for \emph{checking correctness} of proofs, the problem of \emph{provability} can appear to be a very complicated one.
    \end{inparaenum}
\end{exercise}

\(T\) is called a \term{solvable theory} (more precisely---\term{effectively solvable}) if and only if there is an algorithm allowing to check whether some proposition is provable by using the principles of \(T\) or not.
In \cref{Lsolvable}a you proved that \(L\) is a solvable theory.
Still, in \cref{Lsolvable}b you established that it is hard to state whether \CHESS\ is a ``feasibly solvable'' theory or not.
Determining the provability of propositions is a much more complicated task than checking the correctness of ready proofs.
It can be proved that most mathematical theories are unsolvable, the elementary (first-order) arithmetic of natural numbers and set theory included (see, for example, Mendelson [1997]\footnote{\url{http://www.ltn.lv/~podnieks/mlog/ml.htm\#Mendelson1997}}, or click here\footnote{\url{http://www.ltn.lv/~podnieks/gt6.html\#BM6\_3}}).
In other words, there is no algorithm allowing to determine, is some arithmetical proposition provable from the axioms of arithmetic, or not.

\begin{note}
According to the official terminology, effectively solvable sets are called ``recursive sets''.
\end{note}

Normally, mathematical theories contain the negation symbol not. In such theories solving the problem stated in a proposition A means proving either A, or proving notA (``disproving A'', ``refuting A''). We can try to solve the problem by using the enumeration program of the Exercise 1.1.4: let us wait sitting near the computer until A or notA is printed. If A and notA will be printed both, this will mean that T is an inconsistent theory (i.e., using principles of T one can prove some proposition and its negation). In general, we have here 4 possibilities:

\begin{enumerate}[(a)]
    \item A will be printed, but notA will not (then the problem A has a positive solution),
    \item notA will be printed, but A will not (then the problem A has a negative solution),
    \item A and notA will be printed both (then T is an inconsistent theory),
    \item neither A, nor notA will be printed.
\end{enumerate}

In the case d) we may sit forever by our computer, yet nothing interesting will happen: using the principles of T one can neither prove nor disprove the proposition A, and for this reason such a theory is called an incomplete theory. The famous incompleteness theorem proved by Kurt G\"{o}del\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Godel.html}} in 1930 says that most mathematical theories are either inconsistent or incomplete (see Mendelson [1997] or click here).

\begin{exercise}
Show that any (simultaneously) consistent and complete formal theory is solvable. (Hint: use the program of the Exercise 1.1.4, i.e., assume that you have the functions GenerateFirstTheorem() --- returns Text, GenerateNextTheorem() --- returns Text, and implement the function IsProvable(Text) - returns true or false). Where the consistency and completeness come in?
\end{exercise}

\begin{exercise}
\begin{inparaenum}[(a)]
    \item Verify that ``fully axiomatic theories'' are formal theories in the sense of the above general definition.
    (Hint: assume, that you have the following functions: GenerateFirstText() --- returns Text, GenerateNextText() --- returns Text, IsPropositon(Text) --- returns true or false, IsAxiom(Proposition) --- returns true or false, there is a finite list of inference rule names: \({R_1, \ldots, R_n}\), function Apply(RuleName, ListOfPropositions) --- returns Proposition or false, and you must implement the functions IsCorrectProof(ListOfPropositions) --- returns true or false, ExtractTheorem(Proof) --- returns Proposition).
    \item (for smart students) What, if, instead of \({R_1, \ldots, R_n}\), we would have an infinite list of inference rules, i.e., functions GenerateFirstRule(), GenerateNextRule() returning RuleName?
\end{inparaenum}
\end{exercise}

\subsection{Predicate Languages}

History.
For a short overview of the history, see Wikipedia's article on Quantification\footnote{\url{http://en.wikipedia.org/wiki/Quantification}}.

See also:

\begin{itemize}
    \item Aristotle\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Aristotle.html}} (384--322 BC)---in a sense, the ``first logician'', ``\ldots~was not primarily a mathematician but made important contributions by systematizing deductive logic'' (according to MacTutor History of Mathematics archive\footnote{\url{http://www-history.mcs.st-andrews.ac.uk/}}).
    \item Gottlob Frege (1848--1925)---"In 1879 Frege published his first major work \emph{Begriffsschrift, eine der arithmetischen nachgebildete Formelsprache des reinen Denkens} (Conceptual notation, a formal language modelled on that of arithmetic, for pure thought).
    A.George and R Heck write: \ldots~In effect, it constitutes perhaps the greatest single contribution to logic ever made and it was, in any event, the most important advance since Aristotle.
    \ldots  In this work Frege presented for the first time what we would recognise today as a logical system with negation, implication, universal quantification, essentially the idea of truth tables etc." (according to MacTutor History of Mathematics archive).
\item Charles Sanders Peirce (1839--1914): ``\ldots  He was also interested in the Four Colour Problem and problems of knots and linkages\ldots  He then extended his father's work on associative algebras and worked on mathematical logic and set theory. Except for courses on logic he gave at Johns Hopkins University, between 1879 and 1884, he never held an academic post.'' (according to MacTutor History of Mathematics archive).
\item Hilary Putnam. Peirce the Logician. Historia Mathematica, Vol. 9, 1982, pp. 290-301 (an online excerpt\footnote{\url{http://www.jfsowa.com/peirce/putnam.htm}} is available, published by John F. Sowa).
\item Richard Beatty. Peirce's development of quantifiers and of predicate logic. Notre Dame J. Formal Logic, Vol. 10, N 1 (1969), pp. 64-76.
\item Geraldine Brady. From Peirce to Skolem. A Neglected Chapter in the History of Logic. Elsevier Science: North-Holland, 2000, 2000, 625 pp. (online overview at \url{http://www.elsevier.com/wps/find/bookdescription.cws\_home/621535/description\#description)}.
\end{itemize}

When trying to formalize some piece of our (until now---informal) knowledge, how should we proceed?
We have an informal vision of some domain consisting of ``objects''.
When speaking about it, we are uttering various propositions, and some of these propositions are regarded as ``true'' statements about the domain.

Thus, our first formalization task should be defining of some \emph{formal language}, allowing to put all our propositions about the domain in a uniform and precise way.

After this, we can start considering propositions that we are regarding as ``true'' statements about the domain.
There may be an infinity of such statements, hence, we can't put down all of them, and we must organize them somehow.
Some minimum of the statements we could declare simply as axioms, the other ones we could try to derive from the axioms by using some rules of inference.

As the result, we could obtain a formal theory (in the sense of the previous Section).

In mathematics and computer science, the most common approach to formalization is using of the so-
called \term{predicate languages}, first introduced by G.~Frege and C.~S.~Peirce.
(In many textbooks, they are called \term{first-order languages}, see below the warning about second order languages.)

Usually, linguists analyze the sentence ``John loves Britney'' as follows: \emph{John}---subject, \emph{loves}---predicate, \emph{Britney}---object.
The main idea of predicate languages is as follows: instead, let us write \(\mathrm{loves}(\mathrm{John},\mathrm{Britney})\), where \(\mathrm{loves}(x,y)\) is a two-argument predicate, and John, and Britney both are objects.
Following this way, we can write \(=(x, y)\) instead of \(x=y\).
This approach---reducing of the human language sentences to variables, constants, functions, predicates and \term{quantifiers} (see below), appears to be flexible enough, and it is much more uniform when compared to the variety of constructs used in the natural human languages.
A unified approach is much easier to use for communication with computers.

Another example: ``Britney works for BMI as a programmer''.
In a predicate language, we must introduce a 3-argument predicate ``\(x\) works for \(y\) as \(z\)'', or \(\mathrm{works}(x, y, z)\).
Then, we may put the above fact as: \(\mathrm{works}(\mathrm{Britney}, \mathrm{BMI}, \mathrm{Programmer})\).

\subsubsection*{Language Primitives}

Thus, the informal vision behind the notion of predicate languages is centered on the so-called ``domain''---a (non-empty?) collection of ``objects'', their ``properties'' and the ``relations'' between them, that we wish to ``describe'' (or ``define''?) by using the language.
This vision serves as a guide in defining the language precisely, and further---when selecting axioms and rules of inference.

\subsubsection*{Object Variables}

Thus, the first kind of language elements we will need are \term{object variables} (sometimes called also individual variables, or simply, variables).
We need an unlimited number of them:
\[
x, y, z, x_1, y_1, z_1, \ldots
\]
The above-mentioned ``domain'' is the intended ``range'' of all these variables.

\begin{example}
%\label{ex:}
Building a language that should describe the ``domain of people'', we must start by introducing the ``variables for people'': \(x\) denotes an arbitrary person.
% FIXME: add diagram
``Domain of people'' represented as a UML class diagram
\end{example}

\begin{example}
%\label{ex:}
Building the language of the so-called \term{first-order arithmetic}, we are thinking about ``all natural numbers'' as the range of variables: \(0, 1, 2, 3, 4, \ldots\) (\(x\) denotes an arbitrary natural number).
\end{example}

\begin{example}
%\label{ex:}
Building the language of \term{set theory}, we think about ``all sets'' as the range of variables: \(x\) denotes an arbitrary set.
\end{example}

\begin{note}
Since our screens and printers allow only a limited number of pixels per inch, in principle, we
should generate variable names by using a finite set of characters, for example, by using a single letter x:
\[
x, xx, xxx, xxxx, xxxxx, \ldots
\]
\end{note}

\subsubsection*{Object Constants}

The next possibility we may wish to have in our language are the so-called \term{object constants} (sometimes called individual constants, constant letters, or simply, constants)---names or symbols denoting some specific ``objects'' of our ``domain''.

\begin{example}
%\label{ex:}
In our ``language for people'' we may introduce constants denoting particular people: John, Britney etc.
\end{example}

\begin{example}
%\label{ex:}
In the language of first-order arithmetic, we may wish to introduce two constants---0 and 1 to denote ``zero'' and ``one''---two natural numbers having specific properties.
\end{example}

\begin{example}
%\label{ex:}
In the language of set theory, we could introduce a constant denoting the empty set, but there is a way to do without it as well (for details, click here).
\end{example}

\subsubsection*{Function Constants}

In some languages we may need also the so-called \term{function constants} (sometimes called function letters)---names or symbols denoting specific functions, i.e., mappings between ``objects'' of our ``domain'', or operations on these objects.

\begin{example}
%\label{ex:}
In our ``language for people'' we will not use function constants.
\end{example}

\begin{example}
%\label{ex:}
In the language of first-order arithmetic, we will introduce only two function constants ``\(+\)'' and ``\(\cdot\)'' denoting the usual addition and multiplication of natural numbers, i.e., the two-argument functions \(x+y\) and \(x\cdot y\).
\end{example}

\begin{example}
%\label{ex:}
In the language of set theory, we could introduce function constants denoting set intersections \(x\cap y\), unions \(x\cup y\), set differences \(x\setminus y\), power sets \(\mathcal{P}(x)\) etc., but there is a way to do without these symbols as well (for details, click here\footnote{\url{http://www.ltn.lv/~podnieks/gt2.html}}).
\end{example}
In mathematics, normally, we are writing \(f(x,y)\) to denote the value of the function \(f\) for the argument values \(x,y\).
This (the so-called ``prefix'' notation\footnote{\url{https://en.wikipedia.org/wiki/Polish\_notation}}) is a uniform way suitable for functions having any number of arguments: \(f(x)\), \(g(x,y)\), \(h(x,y,z)\) etc.
In our everyday mathematical practice some of the two-argument functions (in fact, operations) are represented by using the more compact ``infix'' notation\footnote{\url{https://en.wikipedia.org/wiki/Infix\_notation}} \((x+y\), \(x\cdot y\) instead of the uniform \(+(x, y)\), \(\cdot(x, y)\), etc.).
\begin{note}
In a sense, object constants can be viewed as a special case of function constants---an object constant is a zero-argument function.
\end{note}

\subsubsection*{Predicate constants}

The last (but the most important!) kind of primitives we need in our language are the so-called predicate constants (sometimes called predicate letters)---names or symbols denoting specific \term{properties} (of) or relations between ``objects'' of our ``domain''.

\begin{note}
Using ``predicate'' as the unifying term for ``property'' and ``relation'' may seem somewhat unusual.
But some kind of such a term is necessary.
Properties are, in fact, unary (i.e., one-argument) ``predicates'', for example, ``\(x\) is red''.
Relations are, in fact, two- or more-argument ``predicates'', for example, ``\(x\) is better than \(y\)'', or ``\(x\) sends \(y\) to \(z\)''.
\end{note}

\begin{example}
%\label{ex:}
In our ``language for people'' we will use the following predicate constants (see the class diagram above):
\begin{itemize}
    \item \(\mathrm{Male}(x)\) means ``\(x\) is a male'';
    \item \(\mathrm{Female}(x)\) means ``\(x\) is a female'';
    \item \(\mathrm{Mother}(x, y)\) means ``\(x\) is mother of y'';
    \item \(\mathrm{Father}(x, y)\) means ``\(x\) is father of y'';
    \item \(\mathrm{Married}(x, y)\) means ``\(x\) and \(y\) are married, \(y\) being wife'';
    \item \(x=y\) --- means ``x an y are the same person''.
\end{itemize}

The first two constants represent, in fact, ``properties'' (or, ``classes'') of our objects.
The remaining four constants represent ``relations'' between our objects.
The term ``predicate'' is used to include both versions.
We do not introduce \(\mathrm{Person}(x)\) as a predicate because our domains consists of persons only.
\end{example}

\begin{example}
%\label{ex:}
It may seem strange to non-mathematicians, yet the most popular relation of objects used in most mathematical theories, is equality (or identity).
Still, this is not strange for mathematicians.
We can select an object \(x\) in our ``domain'' by using a very specific combination of properties and relations of it, and then---select another object \(y\)---by using a different combination.
And after this (sometimes it may take many years to do) we prove that \(x=y\), i.e., that these two different combinations of properties and relations are possessed by a single object.
Many of discoveries in mathematics could be reduced to this form.

In the language of first-order arithmetic, equality ``\(=\)'' is the only necessary predicate constant.
Other ``basic'' relations must be reduced to equality.
For example, the relation \(x<y\) for natural numbers \(x\), \(y\) can be reduced to equality by using the addition function and the formula \(\exists z(x+z+1=y)\).
\end{example}

\begin{example}
%\label{ex:}
In the language of set theory a specific predicate constant ``in'' denotes the set membership relation: ``\(x\) in \(y\)'' means ``\(x\) is a member of \(y\)''.
The equality predicate \(x=y\) also will be used---it means ``the sets \(x\) an \(y\) possess the same members''.
\end{example}

The uniform way of representing suitable for predicates having any number of arguments is again the ``prefix'' notation: \(p(x)\), \(q(x, y)\), \(r(x, y, z)\) etc.
In the real mathematical practice, some of the two-argument predicates are represented by using the more compact ``infix'' notation (so \(x=y\) instead of the uniform \(=(x, y)\), etc.).

Zero-argument predicate constants?
In an interpretation, each such predicate must become either ``true'', or ``false''.
Hence, paradoxically, zero-argument predicate constants behave like ``propositional variables''---they represent assertions that do not possess a meaning, but possess a ``truth value''.

\subsubsection*{Summary of language primitives}

Thus, the specification of a predicate language includes the following \term{primitives}:

\begin{enumerate}
    \item A countable set of object variable names (you may generate these names, for example, by using a single letter ``\(x\)'': \(x, xx, xxx, xxxx, \ldots\)).
    \item An empty, finite, or countable set of object constants.
    \item An empty, finite, or countable set of function constants.
    To each function constant a fixed argument number must be assigned.
    \item A finite, or countable set of predicate constants.
    To each predicate constant a fixed argument number must be assigned.
\end{enumerate}

Different sets of primitives yield different predicate languages. The remaining part of the language definition is common for all predicate languages.

\begin{example}
%\label{ex:}
Our ``language for people'' is based on:
\begin{inparaenum}[(a)]
    \item object variables \(x, y, z, \ldots\);
    \item object constants: John, Britney, \ldots;
    \item function constants: none;
    \item predicate constants: Male(x), Female(x), Mother(x, y), Father(x, y), Married(x, y), x=y.
\end{inparaenum}
\end{example}

\begin{example}
The language of first-order arithmetic is based on: 

\begin{inparaenum}[(a)]
    \item object variables \(x, y, z, \ldots\);
    \item object constants: 0, 1;
    \item function constants: \(x+y\), \(x\cdot y\);
    \item predicate constant: \(x=y\).
\end{inparaenum}
\end{example}

\begin{example}
%\label{ex:}
The language of set theory is based on:

\begin{inparaenum}[(a)]
    \item object variables \(x, y, z, \ldots\);
    \item object constants: none;
    \item function constants: none;
    \item predicate constants: \(x\) in \(y\) (\(x\in y\)), \(x=y\).
\end{inparaenum}
\end{example}

\subsubsection*{Terms and formulas}

By using the language primitives, we can build terms, atomic formulas and (compound) formulas.
\term{Terms} are expressions used to denote objects and functions:

\begin{enumerate}
    \item Object variables and object constants (if any), are terms.
    \item If \(f\) is a \(k\)-place function constant, and \(t_1,\ldots,t_k\) are terms, then the string \(f(t_1,\ldots,t_k)\) is a term.
    \item There are no other terms.
\end{enumerate}

\begin{example}
In our ``language for people'' only variables \(x, y, z, \ldots\), and object constants John, Britney, \ldots\ are terms.
\end{example}

\begin{example}
In the language of first-order arithmetic, for addition and multiplication the ``infix'' notation is used: if \(t_1\), \(t_2\) are terms, then \((t_1+t_2)\) and \((t_1\cdot t_2)\) are terms.
Of course, the object constants 0, 1 and variables \(x, y, z, \ldots\) are terms.
Examples of more complicated terms: \((x+y)\), \(((1+1)\cdot (1+1))\), \((((1+1)\cdot x)+1)\).
\end{example}

\begin{example}
In the language of set theory, variables \(x, y, z, \ldots\)  are the only kind of terms.
\end{example}

If a term does not contain variable names, then it denotes an ``object'' of our ``domain'' (for example, \(((1+1)+1)\) denotes a specific natural number---the number 3).
If a term contains variables, then it denotes a function.
For example, \(\Big(\big((x\cdot x)+(y\cdot y)\big)+1\Big)\) denotes the function \(x^2+y^2+1.\)
(Warning! Note that the language of first-order arithmetic does not contain a function constant denoting the exponentiation \(xy\); thus, we must write \(x\cdot x\) instead of \(x2\).)

Of course, the key element of our efforts in describing ``objects'', their properties and relations, will be assertions, for example, the commutative law in arithmetic: \(\big((x+y)=(y+x)\big)\).
In predicate languages, assertions are called \term{formulas} (or, sometimes, well-formed formulas---``wff''s, or sentences).

\term{Atomic formulas} (in some other textbooks: elementary formulas, prime formulas) are defined as follows:

\begin{enumerate}
    \item If \(p\) is a \(k\)-place predicate constant, and \(t_1, \ldots , t_k\) are terms, then the string \(p(t_1, \ldots , t_k)\) is an atomic formula.
    \item (If you like so,) there are no other atomic formulas.
\end{enumerate}
For the equality symbol, the ``infix'' notation is used: if \(t_1\), \(t_2\) are terms, then \((t_1=t_2)\) is an atomic formula.

\begin{example}
%\label{ex:}
In our ``language for people'', the following are examples of atomic formulas: Male(x), Female(Britney), Male(Britney) (not all formulas that are well formed, must be true!), Father(x, Britney), Mother(Britney, John), Married(x, y).
\end{example}

\begin{example}
%\label{ex:}
Summary of the atomic formulas of the language of first-order arithmetic:

\begin{inparaenum}[(a)]
    \item constants 0 and 1, and all variables are terms;
    \item if \(t_1\) and \(t_2\) are terms, then \((t_1+t_2)\) and \((t_1\cdot t_2)\) also are terms;
    \item atomic formulas are built only as \((t1=t2)\), where \(t_1\) and \(t_2\) are terms.
\end{inparaenum}
\end{example}

\begin{example}
%\label{ex:}
In the language of set theory, there are only two kinds of atomic formulas: \(x\) in \(y\) (\(x\in y\)), and \(x=y\) (where \(x\) and \(y\) are arbitrary variables).
\end{example}
In the language of first-order arithmetic, even by using the only available predicate constant ``\(=\)'', atomic formulas can express a lot of clever things:

\begin{itemize}
    \item \(((x+0)=x)\) (zero is the additive identity);
    \item \(((x+y)=(y+x))\) (addition is commutative);
    \item \(\Big(\big(x+(y+z)\big)=\big((x+y)+z\big)\Big)\) (addition is associative);
    \item \(((x\cdot 0)=0)\) (any number multiplied by zero is zero);
    \item \(((x\cdot 1)=x)\) (one is the multiplicative identity);
    \item \(\big((x\cdot y)=(y\cdot x)\big)\) (multiplication is commutative);
    \item \(\Big(\big(x\cdot (y\cdot z)\big)=\big((x\cdot y)\cdot z\big)\Big)\) (multiplication is associative)
    \item \(\Big(\big((x+y)\cdot z\big)=\big((x\cdot z)+(y\cdot z)\big)\Big)\) (multiplication distributes over addition).
\end{itemize}

\begin{exercise}
As the next step, translate the following assertions into the language of first-order arithmetic (do not use abbreviations!): \(2\cdot 2=4\), \(2\cdot 2=5\), \((x+y)2 = x2+2xy+y2\).
\end{exercise}

\subsubsection*{(Compound) Formulas}

\emph{The following definition is common for all predicate languages.
Each language is specific only by its set of language primitives.}

To write more complicated assertions, we will need compound formulas, built of atomic formulas by using a fixed set of \term{propositional connectives} and \term{quantifiers} (an invention due to G.~Frege and C.~S.~Peirce).
In this book, we will use the following set:

\begin{itemize}
    \item \(\IMPLIES\) (implication symbol, \(B\IMPLIES C\) means ``if \(B\), then \(C\)'', or ``\(B\) implies \(C\)'', or ``\(C\) follows from \(B\)'').
    \item \(\AND\) (conjunction symbol, \(B\AND C\) means ``\(B\) and \(C\)'').
    \item \(\OR\) (disjunction symbol, \(B\OR C\) means ``\(B\), or \(C\), or both'', i.e., the so-called non-exclusive (inclusive) ``or'').
    \item \(\neg\)  (negation symbol, \(\neg B\) means ``not \(B\)'').
    \item \(\forall\)  (universal quantifier, \(\forall xB\) means ``for all \(x\), \(B\)'').
    \item \(\exists\)  (existential quantifier, \(\exists xB\) means ``there exists an \(x\) such that B'').
\end{itemize}

The widely used equivalence connective \(\IFF\) can be derived in the following way: \(B\IFF C\) stands for \(\Big((B\IMPLIES C)\AND (C\IMPLIES B)\Big)\).
If you like using the so-called exclusive ``or'' (``\(B\), or \(C\), but not both''), you could define \(B \text{ XOR } C\) as \(\neg (B\IFF C)\).

Warning! For programmers, conjunction, disjunction and negation are familiar ``logical operations''---unlike the implication that is not used in ``normal'' programming languages.
In programming, the so-called IF-statements, when compared to logic, mean a different thing: in the statement
\begin{verbatim}
if x = y
then z := 17
\end{verbatim}
the condition, \verb|x = y| is, indeed, a formula, but the ``consequent'' \verb|z := 17| is not a formula---it is an executable statement.
In logic, in \(B\IMPLIES C\) (``if \(B\), then \(C\)''), \(B\) and \(C\) both are formulas.

We define the notion of \term{formula} of our predicate language as follows:

\begin{enumerate}
    \item a) Atomic formulas are formulas.
    \item If \(B\) and \(C\) are formulas, then \((B\IMPLIES C)\), \((B\AND C)\), \((B\OR C)\), and \((\neg B)\) also are formulas (here \(B\) and \(C\) are called subformulas).
    \item If \(B\) is a formula, and \(x\) is an object variable, then \((\forall x B)\) and \((\exists x B)\) are also formulas (here \(B\) is called a subformula).
    \item There are no other formulas.
\end{enumerate}

\begin{remark}
%\label{remark:}
For the sake of readability, we will omit any parentheses as long as the meaning is clear.
\end{remark}

See also:
Notes on Logic Notation on the Web by Peter Suber.

\subsubsection{Knowledge representation by means of predicate languages}

\begin{example}
%\label{ex:}
Some simple examples of compound formulas in the language of first-order arithmetic:

Warning! Strictly speaking, the predicate symbols ``\(<\)'', ``\(>\)'', ``\(\leq\)'', ``\(\geq\)'', ``\(\ne\)'' etc., do not belong to the language of first-order arithmetic.

\begin{center}
\begin{tabular}{p{7cm} p{8cm}}
\(\exists u(x=u+u)\)
& ``\(x\) is an even number'' \\
\(\exists u(((x+u)+1)=y))\)
& ``\(x\) is less than \(y\)'' or \(x<y\) \\
\(y\neq0 \AND  \exists u(x=y\cdot u)\)
& ``\(x\) is divisible by \(y\)''; strictly speaking, \(y\neq0\) must be replaced by \(\neg(y=0)\). \\
\(1<x\AND\neg (\exists y\exists z(y<x\AND z<x\AND x=y\cdot z)\)
& ``x is a prime number'', strictly speaking, \(x<y\) must be replaced by \(\exists u((x+u)+1=y))\). \\
\(\forall w\exists x(w<x\AND x\text{ is a prime number})\)
& ``There are infinitely many prime numbers'' (one of the first mathematical theorems, VI century BC), strictly speaking, \(w<x\) must be replaced by \(\exists u((w+u)+1=x)\), and ``x is a prime number'' must be replaced by the above formula.
\(\forall x\forall y(0<y \IMPLIES  \exists z\exists u(u<y \AND  x=y\cdot z+u))\) What does it mean?
\end{tabular}
\end{center}
\end{example}

\begin{example}
Some simple examples of compound formulas in the language of set theory:
\begin{center}
\begin{tabular}{l l}
\(\exists y(y \in x)\)
& ``\(x\) is a non-empty set'' \\
\(\forall z (z \in x\IMPLIES z \in y)\)
& ``\(x\) is a subset of \(y\)'' or \(x\subseteq y\) \\
\(\forall z (z\in x\IFF z\in y)\IMPLIES x=y\)
& What does it mean? Will serve as an axiom! \\
\(\forall y\forall z(y\in x \AND z\in x)\IMPLIES y=z)\)
& ``\(x\) contains zero or one member'' \\
\(\forall u (u\in x\IFF (u\in y \OR u\in z)\)
& ``\(x\) is the union of \(y\) and \(z\)'' or \(x=y\cup z\)
\end{tabular}
\end{center}
\end{example}

Of course, \emph{having a predicate language is not enough} for expressing all of our knowledge formally, i.e., for communicating it to computers.
Computers do not know in advance, for example, how to handle sexes.
We must tell them how to handle these notions by introducing axioms. Thus, the above-mentioned formulas like as (\(\forall x(Male(x) v Female(x))\)), or (\(\forall x(\forall y((Father(x, y))\IMPLIES (Male(x)))\)) will be absolutely necessary as axioms.
As we will see later, language and axioms together make up a theory, i.e., in fact, to formulate all of our knowledge formally, we must create theories.
\begin{exercise}
%\label{}
Exercise 1.2.2. ``Translate'' the following assertions into our ``language for people'':
``x is child of y'';
``x is grand-father of y'';
``x is cousin of y''.
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.2.3. ``Translate'' the following assertions into the language of first-order arithmetic:
``x and y do not have common divisors'' (note: 1 is not a divisor!),
``sqrt(2) is not a rational number''
(Warning! \(\neg \exists p\exists q(sqrt(2)=p/q, and \exists x(x\cdot x=2)\) are not correct solutions. Why?)
\end{exercise}

Warning! Some typical errors!

\begin{enumerate}
    \item 1) Trying to say ``for all \(x>2,\) F(x)'', do not write \(\forall x(x>2\AND F(x))\)---this would imply that \(\forall x(x>2)\)! But, how about x=1? The correct version: \(\forall x(x>2\IMPLIES F(x))\)
    \item 2) Some computer programmers do not like using the implication connective \IMPLIES , trying to write formulas as conditions of IF- or WHILE-statements, i.e., by using conjunction, disjunction and negation only. This ``approach'' makes most logical tasks much harder than they really are! More than that --- some people try saying, for example, ``Persons are not Departments'', as follows: \(\forall x(Person(x)\AND \neg Department(x))\) --- instead of the correct version: \(\forall x(Person(x)\IMPLIES \neg Department(x))\).
    \item 3) Do not use abbreviations at this early stage of your studies. For example, do not write (\(\forall x>2)\exists yF(x,y)\) to say that ``for all x that are >2, there is y such that F(x,y)''. Instead, you should write \(\forall x(x>2\IMPLIES \exists yF(x,y))\). Similarly, instead of (\(\exists a>2)\exists bG(a,b)\), you should write \(\exists a(a>2\AND \exists bG(a,b))\), where \AND  is a conjunction (here, correctly!).

    To say ``there is one and only one x such that F(x)'', you shouldn't write \(\exists !x F(x)\) (at this stage of your studies), you should write, instead, ((\(\exists xF(x))\AND (\forall x1(\forall x2((F(x1)\AND F(x2))\IMPLIES (x1=x2)))\)).

    \item 4) Predicates cannot be substituted for object variables. For example, having 3 predicate constants working(x, y), Person(x), Department(y), do not try writing working(Person(x), Department(y)) to say that ``only persons are working, and only in departments''. The correct verssion: \(\forall x\forall y(working(x, y)\IMPLIES Person(x)\AND Department(y))\).

    \item 5) Trying to say ``each person is working in some department'', do not write \(\forall x\exists y(Person(x)\AND Department(y)\IMPLIES working(x,y)\)). The correct verssion: \(\forall x(Person(x)\IMPLIES \exists y(Department(y)\AND working(x,y)\)). What is the difference?
\end{enumerate}

\begin{exercise}
%\label{}
Exercise 1.2.4. Try inventing your own predicate language. Prepare and do your own Exercise 1.2.2 for it.
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.2.5. In computer science, currently, one the most popular means of knowledge representation are the so-called UML class diagrams and OCL (UML --- Unified Modeling Language, OCL --- Object Constraint Language). The above diagram representing our ``domain of people'' is an example. In our ``language of people'', put down as many axioms of the domain you can notice in the diagram. For example, ``every person is either male, or female'', ``all fathers are males'', ``every person has exactly one mother'', ``a person can marry no more than one person'' etc. 
\end{exercise}

Many-sorted Languages

Maybe, you have to describe two or more kinds of ``objects'' that you do not wish to reduce to ``sub-kinds'' of one kind of ``objects'' (for example, integer numbers and character strings). Then you may need introducing for each of your ``domains'' a separate kind (``sort'') of object variables. In this way you arrive to the so-called many-sorted predicate languages. In such languages: a) each object constant must be assigned to some sort; b) for each function constant, each argument must be assigned to some some sort, and function values must be assigned to a (single) sort; c) for each predicate constant, each argument must be assigned to some sort. In many-sorted predicate languages, the term and atomic formula definitons are somewhat more complicated: building of the term f(t1, \ldots , tk) or the formula p(t1, \ldots , tk) is allowed only, if the sort of the term ti values coincides with the sort of the i-th argument of f or p respectively. And the ``meaning'' of quantifiers depends on the sort of the variable used with them. For example, \(\forall x\) means ``for all values of x from the domain of the sort of x''.  Theoretically, many-sorted languages can be reduced to one-sorted languages by introduding the corresponding predicates Sorti(x) (``the value of x belongs to the sort i''). Still, in applications of logic (for example, in computer science) the many- sorted approach is usually more natural and more convenient. (See Chapter 10. Many-Sorted first-order Logic, by Jean Gallier.)

Warning about second order languages!

In our definition of predicate languages only the following kinds of primitives were used: object variables, object constants,
function constants and predicate constants. You may ask: how about function variables and predicate variables? For, you
may wish to denote by r ``an arbitrary property'' of your ``objects''. Then, r(x) would mean ``x possess the property r'', and you
would be able to say something about ``all properties'', for example, \(\forall r\forall x \forall y(x=y\IMPLIES (r(x)\IFF r(y))\). In this way you would have
arrived at a second order language! In such languages, function and predicate variables are allowed. But properties lead to
sets of objects, for example, \(\{x | r(x)\}\) would mean the set of all objects that possess the property r. But, why should we stop at
the properties of objects? How about ``properties of sets of objects'' etc.? As it was detected long ago, all kinds of sets can be
fully treated only in set theory! Thus, instead of building your own second order language, you should better try applying your
favorite (``first-order'') set theory. An unpleasant consequence: the existence of the (much less significant) notion of second
order languages forces many people to call predicate languages ``first-order languages'' --- to emphasize that, in these
languages, the only kind of variables allowed are object variables.
On the other hand, when trying to implement realistic formal reasoning software, then using of some second order constructs
is, as a rule, more efficient than implementing of a pure first-order reasoning. See, for example, Notices of the AMS, Special
Issue on Formal Proof, Vol. 55, N 11, 2008 (available online).
For details, see: Second-order-logic by Wikipedia. About second order arithmetic see Reverse Mathematics by Wikipedia.
About an almost (but not 100\%) successful attempt to create a set theory ``as simple as logic'' (by Georg Cantor and Gottlob
Frege) click here.

\subsubsection*{Omitting Parentheses}

Our formal definitions of terms and formulas lead to expressions containing many parentheses. Let us recall, for example, our formula expressing that ``x is a prime number'':
\[
((1<x)\AND (\neg (\exists y(\exists z(((y<x)\AND (z<x))\AND (x=(y\cdot z))))))
\]
Such formulas are an easy reading for computers, yet inconvenient for human reading (and even more inconvenient---for putting them correctly). In the usual mathematical practice (and in programming languages) we are allowed to improve the look of our formulas by omitting some of the parentheses --- according to (some of) the following rules:

a) Omit the outermost parentheses, for example, we may write A\IMPLIES (B\IMPLIES C) instead of the formally correct (A\IMPLIES (B\IMPLIES C)). In this way we may improve the final look of our formulas. Still, if we wish to use such formulas as parts of more complicated formulas, we must restore the outermost parentheses, for example: (A\IMPLIES (B\IMPLIES C))\IMPLIES D.

b) We may write, for example, simply: \(x+y+z+u, x\cdot y\cdot z\cdot u, A\AND B\AND C\AND D, AvBvCvD, \exists x\forall y\exists z\forall u(F)\) instead of the more formal \(((x+y)+z)+u, ((x\cdot y)\cdot z)\cdot u, ((A\AND B)\AND C)\AND D, ((AvB)vC)vD, \exists x(\forall y(\exists z(\forall u(F)))).\) In this way we can simplify the above expression ``x is a prime number'' as follows:
\[
(1<x)\AND (\neg (\exists y\exists z((y<x)\AND (z<x)\AND (x=(y\cdot z)))).
\]

c) We can apply the so-called priority rules. For example, the priority rank of multiplications is supposed to be higher than the priority rank of additions. This rule allows writing \(x+y\cdot z\) instead of the more formal \(x+(y\cdot z)\) --- because of its higher priority rank, multiplication must be ``performed first''. The most popular priority rules are the following:

c1) The priority rank of function constants is higher than the priority rank of predicate constants. This allows, for example, writing \(x\cdot y = y\cdot x\) instead of \((x\cdot y)=(y\cdot x)\), or ``\(x\in y\cup z\)'' --- instead of ``\(x\in (y\cup z)\)''.

c2) The priority rank of predicate constants is higher than the priority rank of propositional connectives and quantifiers. This allows, for example, writing y<x \AND  z<x instead of (y<x)\AND (z<x).

c3) The priority rank of quantifiers is higher than the priority rank of propositional connectives. This allows, for example, writing \(\exists x(F)\AND \forall y(G)\) instead of \((\exists x(F))\AND (\forall y(G))\), or writing \(\neg \exists x(F)\) instead of \(\neg (\exists x(F))\).

c4) The priority rank of negations is higher than the priority rank of conjunctions and disjunctions. This allows, for example, writing \(\neg A\AND \neg B instead of (\neg A)\AND (\neg B)\).

c5) The priority rank of conjunctions and disjunctions is higher than the priority rank of implications. This allows, for example, writing A\IMPLIES AvB instead of A\IMPLIES (AvB).

In the usual mathematical practice some additional priority rules are used, but some of them are not allowed in the common programming languages. To avoid confusions do not use too many priority rules simultaneously!

According to the above priority rules, we can simplify the above expression ``x is a prime number'' obtaining a form that is much easier for human reading (but is somewhat complicated for computers to process it):
\[
1<x \AND  \neg \exists y\exists z(y<x \AND  z<x \AND  x=y\cdot z).
\]
As you see, all the above rules are mere abbreviations. In principle, you could use any other set of abbreviation rules accepted by your audience. If computers would do logic themselves, they would not need such rules at all (except, maybe, for displaying some of their results to humans, but why?).

Exercise 1.2.6. ``Translate'' the following assertions into our ``language for people'':
``x and y are siblings'',
``x is brother of y'', ``x is sister of y'',
``x and y are brothers'',
construct formulas expressing as much well-known relationships between people as you can.
But how about the predicate Ancestor(x, y) --- ``x is an ancestor of y''? Could it be expressed as a formula
of our ``language for people''? The first idea --- let us ``define'' this predicate recursively:

\(\forall x\forall y(Father(x, y) v Mother(x, y)\IMPLIES \forall ncestor(x, y))\);
\(\forall x\forall y\forall z(Ancestor(x, y) \AND  Ancestor(y, z)\IMPLIES Ancestor(x, z)).\)

The second rule declares the transitivity property of the predicate. The above two formulas are axioms, allowing to derive the essential properties of the predicate Ancestor(x, y). But how about a single formula F(x, y) in the ``language for people'', expressing that ``x is an ancestor of y''? Such a formula should be a tricky combination of formulas Father(x, y), Mother(x, y) and x=y. And such a formula is impossible! See Carlos Areces. Ph.D. Thesis, 2000, (a non-trivial!) Theorem 1.2.

Exercise 1.2.7. ``Translate'' the following assertions into the language of first-order arithmetic:
``x and y are twin primes'' (examples of twin pairs: 3,5; 5,7; 11,13; 17,19;\ldots ),
``There are infinitely many pairs of twin primes'' (the famous Twin Prime Conjecture),
``x is a power of 2'' (Warning! \(\exists n(x=2n)\) is not a correct solution. Why? Because exponentiation does not
belong to the language of first-order arithmetic.),
``Each positive even integer \(\geq4\) can be expressed as a sum of two primes''
(the famous Goldbach Conjecture).

\subsubsection{Free Variables and Bound Variables}

The above expression ``x is a prime number'':
\[
1<x \AND  \neg \exists y\exists z(y<x \AND  z<x \AND  x=y\cdot z)
\]
contains 3 variables: x --- occurs 4 times in terms, y --- 2 times in terms and 1 time in quantifiers, z --- occurs 2 times in terms and 1 time in quantifiers. Of course, x is here a ``free'' variable - in the sense that the ``truth value'' of the formula depends on particular ``values'' taken by x. On the contrary, the ``truth value'' of the formula does not depend on the particular ``values'' taken by the two ``bound'' variables y and z --- the quantifiers \(\exists y, \exists z\) force these variables to ``run across their entire range''.

More precisely, first, we will count only the occurrences of variables in terms, not in quantifiers. And second, we will define a particular occurrence ox of a variable x in (a term of) a formula F as a free occurrence or a bound occurrence according to the following rules:

a) If F does not contain quantifiers \(\exists x, \forall x\), then ox is free in F.

b) If F is \(\exists xG or \forall xG\), and ox is free in G, then ox is bound in F.

c1) If F is G\AND H, GvH, or G\IMPLIES H, and ox is free in G (or in H), then ox is free in F.

c2) If F is \(\neg G, \exists yG, or \forall yG\), where y is not x, and ox is free in G, then ox is free in F.

d1) If F is G\AND H, GvH, or G\IMPLIES H, and ox is bound in G (or in H), then ox is bound in F.

d2) If F is \(\neg G, \exists yG, or \forall yG\) (where y is any variable, x included), and ox is bound in G, then ox is bound in F.

Thus, the above formula \(1<x \AND  \neg \exists y\exists z(y<x \AND  z<x \AND  x=y\cdot z)\) contains 4 free occurrences of x, 2 bound occurrences of y, and 2 bound occurrences of z.

Exercise 1.2.8. Verify that an occurrence of x in F cannot be free and bound simultaneously. (Hint: assume that it is not the case, and consider the sequence of all sub-formulas of F containing this particular occurrence of x.)

Formally, we can use formulas containing free and bound occurrences of a single variable simultaneously, for example, \(x>1\IMPLIES \exists x(x>1)\). Or, many bound occurrences of a single variable, for example, (\(\forall xF(x) \AND \exists xG(x)) v \forall xH(x)\) means the same as \((\forall xF(x) \AND  \exists yG(y)) v \forall zH(z) \).Still, we do not recommend using a single variable in many different roles in a single formula. Such formulas do not cause problems for computers, but they may become inconvenient for human reading.

Let us say, that x is a free variable of the formula F, if and only if F contains at least one free occurrence of x, or F does not contain occurrences of x at all.

If a formula contains free variables, i.e., variables that are not bound by quantifiers (for example: x=0 v x=1), then the ``truth value'' of such formulas may depend on particular values assigned to free variables.  For example, the latter formula is ``true'' for x=1, yet it is ``false'' for x=2. Formulas that do not contain free occurrences of variables, are called closed formulas, for example:
\[
\forall w\exists x( w<x \AND  x is a prime number).
\]
Closed formulas represent ``definite assertions about objects of theory'', they are expected to be (but not always really are) either ``true'', or ``false''.

\subsubsection{Term Substitution}

To say that \(x\) is a free variable of the formula \(F\), we may wish to write \(F(x)\) instead of simply \(F\). Replacing all free occurrences of \(x\) by a term \(t\) yields an ``instance'' of the formula F.
It would be natural to denote this ``instance'' by \(F(t)\).

For example, if F(x) is \(\exists y(y+y=x) and t is z\cdot z+z, then F(t), or F(z\cdot z+z) will denote \exists y(y+y=z\cdot z+z).\) However, if \(t\) would be \(y\cdot y+y\), then \(F(t)\), or \(F(y\cdot y+y)\) would be \(\exists y(y+y=y\cdot y+y)\).  Is this really \(F(y\cdot y+y)\)?  Thus, sometimes, this operation can lead to crazy results. Another example: in our expression "x is a prime number``, let us replace x by y. Will the resulting formula mean ''y is a prime number"? Let's see: \[1<y \AND  \neg \exists y\exists z(y<y \AND  z<y \AND  y=y\cdot z).\] Since y<y is always false, the second part \(\neg \exists y\exists z(\ldots )\) is true, hence, the latter formula means simply that ``1 is less than y'', and not that ``y is a prime number''.

Of course, we failed because we replaced a free variable x by a variable y in such a way that some free occurrence of x became bound by a quantifiers for y (\(\exists y\)). In this way we deformed the initial meaning of our formula.

The following simple rule allows to avoid such situations. Suppose, x is a free variable of the formula F.  We will say that the substitution F(x/t) (i.e., the substitution of the term t for x in the formula F) is admissible, if and only if no free occurrences of x in F are located under quantifiers that bind variables contained in t. If the substitution F(x/t) is admissible, then, by replacing all free occurrences of x in F by t, of course, we do not change the initial meaning of the formula F(x), and hence, we may safely denote the result of this substitution by F(t).

Exercise 1.2.9. Is x/y an admissible substitution in the following formulas? Why?
\[x=0 v \exists y(y>z)\]
\[x=0 v \exists y(y>x)\]

Exercise 1.2.10. a) Mathematicians: think over the analogy between bound variables in logic and bound
variables in sum expressions and integrals.
b) Programmers: think over the analogy between bound variables in logic and loop counters in programs.

\subsection{Axioms of Logic: Minimal System, Constructive System and Classical System}

\subsubsection*{The Problem of Reasoning}

Now we go on to the second phase of formalization: after having defined a formal language (predicate language) allowing to put down propositions about our domain of interest, we must formulate some of the propositions as axioms, and must introduce some rules of inference allowing to derive other statements that are ``true'' of our domain.

Indeed, having formulated some fragment of our knowledge as a set of axioms A1, \ldots , An in some
predicate language L, we do not think that A1, \ldots , An represent all statements that are true of the objects
we are trying to investigate. Many other statements will follow from A1, \ldots , An as consequences.

Example. Assume, we have formulated the following axioms in our ``language for people'':
\(\forall x\neg (Male(x)\AND Female(x)); \forall x(Male(x)vFemale(x)),\) and the following facts: Male(John);
Female(Britney). Then we do not need to formulate \(\neg Female(John)\) ; \(\neg\) Male(Britney) as separate facts.
These facts can be derived from already registered facts.
The problem of reasoning: what does it mean: ``formula F follows from A1, \ldots , An''? The answer must be
absolutely precise, if we wish to teach reasoning to computers.

\subsubsection*{Solution of the Problem}

First of all, let us notice that there are axioms and rules of inference that are applicable to any predicate
languages, independently of the specific features of their domains. Such axioms and rules could be called
``generally valid''.

For example, assume, some formula F has the following form:
\[
(B\IMPLIES D)\IMPLIES ((C\IMPLIES D)\IMPLIES (BvC\IMPLIES D)),
\]
where B, C, D are some formulas.
Then \(F\) is ``true'' independently of the specific facts represented in the formulas B, C, D.

Similarly, the following rule of inference MP is applicable independently of the facts represented in the
formulas B, C:
Having derived the formulas B, B\IMPLIES C, derive the formula C.
If we have B\IMPLIES D and B\IMPLIES D already derived, then---by applying the rule MP to the above formula F---we derive that BvC\IMPLIES D.

Now, we will try formulating a complete set of ``generally valid'' principles (axioms and rules of inference) of ``logically correct reasoning''. ``Generally valid'' means that these principles will be applicable to any predicate language. i.e., for any fixed predicate language L, we wish to formulate a uniform list of logical axioms and inference rules that would allow formalization of principles of reasoning that are ``valid'' for all languages. Such principles are called sometimes ''pure logical" principles. The existence of such general principles (and even, in a sense, a complete system of them) is the result of a 2500 year long history of great discoveries (or inventions? --- see below).

Aristotle (384-322 BC), Gottlob Frege (1848-1925), Charles Sanders Peirce (1839-1914).
Bertrand Russell (1872-1970) --- "The Principia Mathematica is a three-volume work on the foundations of mathematics,
written by Bertrand Russell and Alfred North Whitehead and published in 1910-1913. It is an attempt to derive all
mathematical truths from a well-defined set of axioms and inference rules in symbolic logic. The main inspiration and
motivation for the Principia was Frege's earlier work on logic, which had led to some contradictions discovered by Russell."
(according to Wikipedia, the Free Encyclopedia).
David Hilbert (1862-1943), Wilhelm Ackermann (1896-1962).
D.Hilbert, W.Ackermann. Grundzuege der theoretischen Logik. Berlin (Springer), 1928 (see also: Hilbert and Ackermann's
1928 Logic Book by Stanley N. Burris).

The first version of logical axioms was introduced in 1879 by G. Frege in his above-mentioned
Begriffsschrift. The next important version was proposed in 1910-1913 by B.Russell and A.Whitehead in
their book Principia Mathematica. And finally, in 1928 D.Hilbert and W.Ackermann published in their
above-mentioned book, in a sense, the final version of logical axioms. Modifications of this version are
now used in all textbooks of mathematical logic.

In our version, the axioms will be represented by means of the so-called axiom schemas (computer
scientists may call them templates). Each schema (template) represents an infinite, yet easily recognizable
collection of single axioms. For example, schema L3: B\AND C\IMPLIES B may represent the following axioms
(``instances of the schema'') in the language of first-order arithmetic:
x=y \AND  x=x\IMPLIES x=y,
\(1\cdot 1=1 \AND  1+1=1+1\IMPLIES 1\cdot 1=1\),
and many other axioms: take any formulas B, C, and you will obtain an axiom B\AND C B\AND C\IMPLIES B.

We will not specify properties of the equivalence connective in axioms. We will regard this connective as a derived one: B\IFF C will be used as an abbreviation of (B\IMPLIES C)\AND (C\IMPLIES B).

\subsubsection*{Axioms of Logic}

Suppose, we have some predicate language L. We adopt the following 15 axiom schemas as the logical axioms for the language L.

In the axiom schemas \(L_1\)--\(L_{11}\) below, B, C and D are any formulas in the language \(L\).

The first two axiom schemas L1, L2 represent the ``definition'' of the implication connective:

\begin{axiom}
%\label{ax:}
Let \(B,C\) be formulas of \(L\).
Then \(B\IMPLIES (C\IMPLIES B)\).
\end{axiom}
(What does it mean?)

\begin{axiom}
%\label{ax:}
Let \(B,C,D\) be formulas of \(L\).
Then \((B\IMPLIES (C\IMPLIES D))\IMPLIES ((B\IMPLIES C)\IMPLIES (B\IMPLIES D))\).
\end{axiom}
(What does it mean?).

The following axiom schemas L3-L5 represent the ``definition'' of the AND-connective (conjunction):

L3: B\AND C\IMPLIES B (what does it mean?),

L4: B\AND C\IMPLIES C (what does it mean?),

L5: B\IMPLIES (C\IMPLIES B\AND C) (what does it mean?).

The following axiom schemas L6-L8 represent the ``definition'' of the (non-exclusive) OR-connective (disjunction):

L6: B\IMPLIES BvC (what does it mean?),

L7: C\IMPLIES BvC (what does it mean?),

L8: (B\IMPLIES D)\IMPLIES ((C\IMPLIES D)\IMPLIES (BvC\IMPLIES D)) (what does it mean?).

The next xiom schema L9 represents the ``definition'' of the NO-connective. In fact, it is a formal version of a proof method well-known in mathematics --- refutation by deriving a contradiction (Reductio ad absurdum):

L9: \((B\IMPLIES C)\IMPLIES ((B\IMPLIES \neg C)\IMPLIES \neg B)\) (what does it mean?).

The next axiom schema L10 represents the famous principle ``Contradiction Implies Anything'' (Ex contradictione sequitur quodlibet, or Ex falso sequitur quodlibet):

L10:\( \neg B\IMPLIES (B\IMPLIES C)\) (what does it mean?).

The following axiom schema L11 represents the famous Law of the Excluded Middle (Tertium non datur):

L11: \(B\OR\neg B\) (what does it mean?).

The above 11 schemas (plus the Modus Ponens rule of inference, see below) represent the classical propositional logic in the language L.

Now, the ``definitions'' of the universal and existential quantifiers follow.
In the following axiom schemas L12, L13, F is any formula, and t is a term such that the substitution F(x/t)
is admissible (in particular, t may be x itself):

L12: \(\forall xF(x)\IMPLIES F(t)\) (in particular, \(\forall xF(x)\IMPLIES F(x)\), what does it mean?),

L13: \(F(t)\IMPLIES \exists xF(x)\) (in particular, \(F(x)\IMPLIES \exists xF(x), what does it mean?)\).

In the following schemas L14, L15, F is any formula, and G is a formula that does not contain x as a free
variable:
L14: \(\forall x(G\IMPLIES F(x))\IMPLIES (G\IMPLIES \forall xF(x))\) (what does it mean?),
L15: \(\forall x(F(x)\IMPLIES G)\IMPLIES (\exists xF(x)\IMPLIES G)\) (what does it mean?).
Rules of Inference
In the following rules of inference, B, C and F are any formulas.
Modus Ponens: \(B\IMPLIES C, B \vdash C\) (what does it mean?).
Generalization: \(\derive{F(x)}{\forall xF(x)}\) (what does it mean?).

This list of logical axioms and rules of inference represents the so-called \term{classical predicate logic} in the predicate language L (or, simply---the \term{classical logic} in the language L).

\subsubsection*{First-order theories}

Having defined our predicate language L, and having formulated for L all the logical axioms and rules of inference, do we need more?

To complete the formalization of our informal vision of our domain of interest, we must formulate at least some specific axioms describing the specific features of the domain. Logical axioms and rules of inference are valid for any domains, i.e., they are ``content-free'' in the sense that, by using them only, one cannot derive specific information about the domain.

For example, one cannot derive from any logic, that \(\forall x (Male(x) v Female(x))\). To communicate this fact to the computer, we must formulate it as a specific axiom.

And, as we will prove in Section 4, we will never need introducing of specific rules of inference. All we need are the two logical rules of inference---Modus Ponens and Generalization.

Thus, as the result of the formalization process, we will obtain the so-called first-order theories.

Each first-order theory T includes:

a) a specific predicate language L(T),

b) logical axioms and rules of inference for this language (classical or constructive version may be adopted),

c) a set of specific (non-logical) axioms of T.

As the first example, let's use our ``language for people'' to build a ``theory for people''.

Instances of logical axioms for the ``language for people'':

L1: \(\forall x(Male(x)\IMPLIES (Female(x)\IMPLIES Male(x)));\)

L6: \(\forall x\forall y(Mother(x, y)\IMPLIES Mother(x, y) v Father(x, y));\)

L11: \(Male(John) v \neg Male(John);\)

L12: \(\forall x(Female(x))\IMPLIES Female(Britney));\)

etc.

And let's introduce the following non-logical axioms:

\(\forall x (Male(x) v Female(x));\)

\(\forall x \neg (Male(x) \AND  Female(x);\)

\(\forall x\forall y (Father (x, y)\IMPLIES Male(x));\)

\(\forall x(\forall y(\forall z((Father(x, z)\AND Father(y,z))\IMPLIES (x=y)))) \ldots \)

Exercise 1.3.1. Extend this list of axioms as far as you can. Is your list complete? What do you mean by ``complete''?

Another example of a first-order theory --- the so-called first-order arithmetic PA (also called Peano arithmetic):

The language of PA:
a) The constants 0 and 1, and all variables are terms.
b) If \(t_1\) and \(t_2\) are terms, then \((t1+t2)\) and \((t1\cdot t2)\) also are terms.
c) Atomic formulas are built as (t1=t2), where t1 and t2 are terms.
Since we can use, for example, the expression 2x2-3y2-1=0 as a shortcut for \((1+1)\cdot x\cdot x=(1+1+1)\cdot y\cdot y+1\), we can say simply
that, in first-order arithmetic, atomic formulas of are arbitrary Diophantine equations.
Instances of logical axioms for the language of first-order arithmetic:
L1: x=0 \IMPLIES  (y=1 \IMPLIES  x=0);
L6: x=y \IMPLIES  x=y v z=1;
L11: \(0=1 v \neg (0=1)\);
L12: \(\forall x(x=1) \IMPLIES  x=1\);
etc.
The specific (non-logical) axioms of first-order arithmetic:
x=x,
x=y\IMPLIES y=x,
x=y\IMPLIES (y=z\IMPLIES x=z),
x=y\IMPLIES x+1=y+1,
\(\neg (0=x+1),\)
x+1=y+1\IMPLIES x=y,
x+0=x,
x+(y+1)=(x+y)+1,
\(x\cdot 0=0\),
\(x\cdot (y+1)=(x\cdot y)+x\),
\(B(0) \AND  \forall x(B(x)\IMPLIES B(x+1))\IMPLIES \forall xB(x)\), where B is any formula.
The axioms 7-10 represent recursive definitions of addition and multiplication. As the last the so-called induction schema is
listed. (To read more --- click here.)
To read about a very simple system of axioms of set theory --- click here. Unfortunately, from such a simple system
contradictions can be derived (the so-called Russell's Paradox). Corrected versions of axioms of set theory are much more
complicated (see, for example, the most popular system --- Zermelo-Fraenkel axioms).

\subsubsection{Proofs and Theorems}
%\label{}

In general, any sequence of formulas \(F_1, F_2, \ldots , F_m\) could be regarded as a (correct or incorrect) \term{formal proof} (or simply, a proof) of its last formula, \(F_m\).
In a correct proof, formulas can play only the following roles:

\begin{description}
    \item[Axioms.] Some formulas may be instances of logical or non-logical axioms.
    \item[Consequences] of earlier formulas, obtained by using rules of inference. For example, if F25 is A, and F34 is A\IMPLIES B, and F51 is B, then we can say that F51 has been obtained from F25 and F34 by using the Modus Ponens rule. Or, if F62 is C(x), and F63 is \(\forall xC(x)\), then we can say that F63 has been obtained from F62 by using the Generalization rule.
    \item[Hypotheses.] Some formulas may appear in the proof as ``proved elsewhere'', or even without any justification, simply by assuming that they are ``true''.
\end{description}

Thus, the following notation can describe the real status of a formal proof:
\[
[T]: \derive{A_1, A_2, \ldots , A_n}{B},
\]
where \(T\) is a first-order theory (it determines which formulas are axioms and which are not), \(A1, A2, \ldots , An\) are \emph{all} the hypotheses used in the proof, and \(B\) is the formula proved by the proof.
Each formula in such a proof must be either an axiom, or a hypothesis from the set \(A_1, A_2, \ldots , A_n\), or it must be obtained from earlier formulas (in this proof) by using a rule of inference.
You may wish to read the above notation as ``in theory T, by using formulas \(A_1, A_2, \ldots , A_n\) as hypotheses, the formula B can be proved''.

For the first examples of real formal proofs see the next Section, Theorem 1.4.1 and Theorem 1.4.2.

In the real mathematical practice, when proving \([T]: A1, A2, \ldots , An \vdash B\), we may apply some theorem Q that already has been proved earlier. If we would simply insert Q into our formal proof, then, formally,
this would yield only a proof of \([T]: A1, A2, \ldots , An, Q \vdash B\), i.e., Q would be qualified as a hypothesis. To
obtain the desired formal proof of \([T]: A1, A2, \ldots , An \vdash B\), we must insert not only Q itself, but the entire
proof of Q! In this way we obtain the following

\begin{theorem}\label{131}
If there is a proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n, Q\}}{B}\), and a proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n\}}{Q}\), then there is a proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n\}}{B}\).
\end{theorem}
\begin{proof}
A proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n, Q\}}{B}\) is a sequence of formulas \(F_1, F_2, \ldots, Q, \ldots, F_m, B\), and a proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n\}}{Q}\) is some sequence of formulas \(G_1, G_2, \ldots , G_p, Q\).
Let us replace \(Q\) by \(G_1, G_2, \ldots, G_p, Q\):
\[
F_1, F_2, \ldots , G_1, G_2, \ldots, G_p, Q, \ldots, F_m, B,
\]
and eliminate the duplicate formulas.
This sequence is a proof of \([T]: \derive{\{A_1, A_2, \ldots, A_n\}}{B}\).
\end{proof}

If, in some proof, hypotheses are not used at all, then we may write simply \([T]: \emptyset\derive{}{B}\), or even \(\derive{T}{B}\), and say that B is a \term{theorem} of theory \(T\).
Of course, using axioms directly almost never can prove real complicated theorems. Still, we can retain our simple formal definition of the notion of theorem because of the following.

\begin{corollary}
%\label{cor:}
If there is a proof of [T]: A1, A2, \ldots , An \(\vdash\) B, and proofs of [T]: \(\vdash\) A1, [T]: \(\vdash\) A2, \ldots , [T]: \(\vdash\)
An, then there is a proof of [T]: \(\vdash\) B.
\end{corollary}
\begin{proof}
Immediately, by \cref{131}.
\end{proof}

Some of the logical axioms are ``wrong, but useful''!

The axioms L1, L2 represent the (currently) most popular version of ``defining'' the implication connective. About other (equivalent) versions --- containing 3 or 4 axioms --- see Hilbert, Bernays [1934] (Chapter III) and Exercise 1.5.2.

The axiom L9 represents the (currently) most popular version of ``defining'' the negation connective.
About other (equivalent) versions --- see Hilbert, Bernays [1934] (Chapter III), Exercise 2.4.2, and Section 7.1.

Three of the above axiom schemas seem to be (at least partly) problematic.

For example, how do you find the funny axiom L10: \(\neg B\IMPLIES (B\IMPLIES C)? If \neg\) B and B were true simultaneously, then anything were true? Ex contradictione sequitur quodlibet? Is this a really ``true'' axiom? Of course, it is not. Still, this does not matter: we do not need to know, were C ``true'' or not, if \(\neg\) B and B were ``true'' simultaneously. By assuming that ``if \(\neg\) B and B were true simultaneously, then anything were true'' we greatly simplify our logical apparatus. For example, we will prove in Section 2.6 that, in the classical logic, \(\neg \neg B\IMPLIES B\). This simple formula can't be proved without the ``crazy'' axiom L10 (see Section 2.8).

In fact, the first axiom L1: B\IMPLIES (C\IMPLIES B) also is funny. If B is (unconditionally) true, then B follows from C, even if C has nothing in common with B? Moreover, in Exercise 1.4.2(d) we will see that the axioms L1, L9 allow proving that \(\neg B, B \vdash \neg C, i.e., if \neg B\) and B were true simultaneously, then anything were false (thus, in a sense, L1 contains already 50\% of L10!). After this, could we think of L1 as a really ``true'' axiom? Of course, we can't. Still, this does not matter: if B is (unconditionally) true, then we do not need to know, follows B from C or not. By assuming that ``if B is true, then B follows from anything'' we greatly simplify our logical apparatus.

The above two phenomena are called paradoxes of the material implication, see Paradoxes of Material Implication by Peter Suber, and Falsity Implies Anything by Alexander Bogomolny.

May our decision to ``greatly simplify'' the logical apparatus have also some undesirable consequences?  Let us consider the following formula F(x): \(\forall y(child(x, y)\IMPLIES Female(y))\).  It seems, F(x) is intended to mean: ``All the children of x are female''. However, in our system of logic, F(x) is regarded as true also, if x does not have children at all! If you do not have children at all, then all your children are female! Or male? Or smart? Etc. Seems funny, but is, in fact, harmless\ldots 

\subsubsection{Constructive Logic}
%\label{}

Still, the most serious problem is caused by the axiom L11: \(Bv\neg B\)---the Law of the Excluded Middle.  How can we think of L11 as a ``true'' axiom, if (according to G\"{o}del's Incompleteness Theorem) each sufficiently strong consistent theory contains undecidable propositions? i.e., we postulate that either B, or \(\neg B\) ``must be true'', yet for some B we cannot prove neither B, nor \(\neg\) B! Knowing that Bv\(\neg\) B is ``true'' may inspire us to work on the problem, but it may appear useless, if we do not succeed\ldots  Should we retain L11 as an axiom after this?

Some other strange consequences of L11 also should be mentioned (see Exercise 2.6.4):

\begin{enumerate}
    \item \(Bv(B\IMPLIES C)\),
    \item \((B\IMPLIES C)v(C\IMPLIES B)\),
    \item \(((B\IMPLIES C)\IMPLIES B)\IMPLIES B\) (the so-called Peirce's Law).
\end{enumerate}

For these (and some other) reasons some people reject L11 as a ``valid'' logical axiom.

The above list of 15 axiom schemas as it stands is called the \term{classical logic}.

By excluding L11 from the list the so-called constructive (historically, and in most textbooks --- intuitionistic) logic is obtained. As a concept, it was introduced by Luitzen Egbertus Jan Brouwer in 1908:

L. E. J. Brouwer. De onbetrouwbaarheid der logische principes (in Dutch - `` The unreliability of the logical principles'' ), Tijdschrift voor Wijsbegeerte, 2 (1908), pp.152-158.

Brouwer's main objection was against non-constructive proofs which are enabled mainly by ``improper'' use of the Law of the Excluded Middle.  For elegant examples of non-constructive proofs see Constructive Mathematics by Douglas Bridges in Stanford Encyclopedia of Philosophy.  Note. A similar kind of non-constructive reasoning is represented by the so-called Double Negation Law: \(\neg \neg B\IMPLIES B\), see Section 2.6.  As a formal system, the intuitionistic logic was formulated by Arend Heyting in 1930: A. Heyting. Die formalen Regeln der intuitionistischen Mathematik. Sitzungsberichte der Preussischen Akademie der Wissenschaften, Physikalisch-mathematische Klasse, 1930, pp.42-56.  The constructive concept of logic differs from the classical one mainly in its interpretation of disjunction and existence assertions:

--- To prove BvC constructively, you must prove B, or prove C. To prove BvC by using the classical logic, you are allowed to assume \(\neg\) (BvC) as a hypothesis to derive a contradiction. Then, by the Law of the Excluded Middle (BvC)v\(\neg\) (BvC) you obtain BvC. Having only such a ``negative'' proof, you may be unable to determine, which part of the disjunction BvC is true --- B, or C, or both. Knowing that BvC is ``true'' may inspire you to work on the problem, but it may appear useless, if you do not succeed\ldots

--- To prove \(\exists\) xB(x) constructively, you must provide a particular value of x such that B(x) is true. To prove \(\exists\) xB(x) by using the classical logic, you are allowed to assume \(\forall\) x\(\neg\) B(x) as a hypothesis to derive a contradiction. Then, by the Law of the Excluded Middle \(\exists\) xB(x) v \(\neg\) \(\exists\) xB(x) you obtain \(\exists\) xB(x). Having only such a ``negative'' proof, you may be unable to find a particular x for which B(x) is true. Knowing that \(\exists\) xB(x) is ``true'' may inspire you to work on the problem, but it may appear useless, if you do not succeed\ldots

\begin{note}
%\label{}
Note. Informally, we may regard existence assertions as ``huge disjunctions''. For example, in the language of first-order arithmetic, \(\exists\) xB(x) could be ``thought'' as B(0)vB(1)vB(2)v\ldots , i.e., as an infinite ``formula''. Thus, the above two theses are, in a sense, ``equivalent''.
\end{note}

The constructive (intuitionist) logic is one of the great discoveries in mathematical logic --- surprisingly, a complete system of constructive reasoning (as we will see later, in Section 4.4) can be obtained simply by dropping the Law of the Excluded Middle from the list of valid logical principles.

See also Intuitionistic Logic by Joan Moschovakis in Stanford Encyclopedia of Philosophy.

Luitzen Egbertus Jan Brouwer (1881-1966): "He rejected in mathematical proofs the Principle of the Excluded Middle, which states that any mathematical statement is either true or false. In 1918 he published a set theory, in 1919 a measure theory and in 1923 a theory of functions all developed without using the Principle of the Excluded Middle." (according to MacTutor History of Mathematics archive). "Como Heinrich Scholz solia decir en sus cursos: no son ni Heidegger ni Sartre los verdaderos renovadores de la filosofia, sino Brouwer porque sólo él ha atacado el bastión dos veces milenario del platonismo: la concepción de los entes matematicos como cosas en si." (quoted after Andrés R. Raggio, Escritos Completos, Prometeo Libros, 2002).

\subsubsection{Minimal Logic}
%\label{}

By excluding both L10 and L11 the so-called minimal logic is obtained. It was introduced by Ingebrigt Johansson in 1936: I.Johansson. Der Minimalkalkuel, ein reduzierter intuitionistischer Formalismus. Compositio Mathematica, 1936, Vol. 4, N1, pp.119-136.  As a separate concept, the minimal logic is much less significant than the constructive logic. Indeed, since it allows proving of \(\neg B, B \vdash \neg C\) (in a sense, 50\% of L10!), dropping of L10 is not a very big step.

\subsubsection{Consistency}
%\label{}

Sometimes, a seemingly plausible set of axioms allows deriving of contradictions (the most striking example --- Russell's paradox in the ``naive'' set theory). A formula F is called a contradiction in the theory T, if and only if [T]: \(\vdash\) F and [T]: \(\vdash \neg F\), i.e., if T proves and disproves F simultaneously. Theories containing contradictions are called inconsistent theories. Thus, T is called a consistent theory; if and only if T does not allow deriving of contradictions.

Normally, for a first-order theory, the set of all theorems is infinite, and, therefore, consistency cannot be verified empirically. We may only hope to establish this desirable property by means of some theoretical proof (click here for a more detailed discussion of this problem).

For theories adopting the above logical axioms, inconsistency is, in a sense, ``the worst possible property''.  Indeed, the axiom L10: \(\neg\) B\IMPLIES (B\IMPLIES C) says that if a theory allows deriving a contradiction, then, in this theory, anything is provable. In Section 2.4 we will --- without L10 --- prove 50\% of it: \(\neg B\IMPLIES (B\IMPLIES \neg C).\) Thus, without L10: if a theory allows deriving a contradiction, then, in this theory, anything is disprovable.

Is consistency enough for a theory to be ``perfect''?
In Section 4.3 we will prove the so-called Model Existence Theorem: if a first-order theory is consistent, then there is a ``model'' (a kind of ``mathematical reality'') where all its axioms and theorems are ``true''.

\subsubsection{Completeness}
%\label{}

If a formula contains free variables, i.e., variables that are not bound by quantifiers (for example: x=0 v x=1), then the ``truth value'' of such formulas may depend on particular values assigned to free variables.  For example, the latter formula is ``true'' for x=1, yet it is ``false'' for x=2. Formulas that do not contain free occurrences of variables, are called \term{closed formulas}, for example:
\[
\forall w\exists x( w<x \AND  x\text{ is a prime number}).
\]
Closed formulas represent ``definite assertions about the objects of our theory'', they are expected to be either ``true'', or ``false''. Or, in a first-order theory, they are expected to be either provable, or disprovable (refuted). The above closed formula (stating that ``there are infinitely many prime numbers'') is provable---in first-order arithmetic.

\(T\) is called a complete theory, if and only if for each closed formula F in the language of T: [T]: \(\vdash\) F or [T]: \(\vdash \neg F\), i.e., if and only if T proves or disproves any closed formula of its language. In other words: a complete theory can solve any problem from the domain of its competence.

In an incomplete theory, some closed formulas (``definite assertions about the objects of theory'') can be neither proved, not disproved. Thus, an incomplete theory can't solve some of the problems from the domain of its competence.

Formally, according to this definition, an inconsistent theory is complete. Indeed, the axiom L10: \(\neg B\IMPLIES (B\IMPLIES C)\) says that if a theory allows deriving a contradiction, then, in this theory, anything is provable, i.e., it is a complete theory. In Section 2.4 we will --- without L10 --- prove 50\% of it: \(\neg B\IMPLIES (B\IMPLIES \neg C)\). Thus, even without L10: if a theory allows deriving a contradiction, then, in this theory, anything is disprovable, i.e., it is a complete theory.  Of course, if T would be both consistent and complete, then we could call it ``absolutely perfect''.

Unfortunately, G\"{o}del's incompleteness theorem says that fundamental mathematical theories are
either inconsistent or incomplete (see Mendelson [1997] or click here), i.e., none of them is "absolutely
perfect".

\begin{exercise}
%\label{}
Re-formulate the above axiom system for a many-sorted predicate language (or, see Chapter 10. Many-Sorted first-order Logic, by Jean Gallier.)
\end{exercise}

\subsection{The Flavor of Proving Directly}

\begin{theorem}
%\label{}
\([L1, L2, MP]: \vdash A\IMPLIES A\) for any formula A.
\end{theorem}

What does it mean? It's the so-called \term{reflexivity property of implication}.

The following sequence of formulas represents a proof of the formula \(A\IMPLIES A\).

(1) (A\IMPLIES ((C\IMPLIES A)\IMPLIES A))\IMPLIES ((A\IMPLIES (C\IMPLIES A))\IMPLIES (A\IMPLIES A)) It's the axiom schema L2: (B\IMPLIES (C\IMPLIES D))\IMPLIES ((B\IMPLIES C)\IMPLIES (B\IMPLIES D)), with B = A, C = C\IMPLIES A, D = A.

(2) A\IMPLIES ((C\IMPLIES A)\IMPLIES A) It's the axiom schema L1: B\IMPLIES (C\IMPLIES B), with B = A, C = C\IMPLIES A.

(3) (A\IMPLIES (C\IMPLIES A))\IMPLIES (A\IMPLIES A) It follows from (1) and (2) by Modus Ponens.

(4) A\IMPLIES (C\IMPLIES A) It's the axiom schema L1: B\IMPLIES (C\IMPLIES B), with B = A, C = C.

(5) A\IMPLIES A It follows from (3) and (4) by Modus Ponens.

As you can see, the proof is easy to verify, but it could be hard to build it from scratch.
``Why'' should we take ``the axiom L2 with B = A, C = C\IMPLIES A, D = A'' for (1)?
How could one invent a proof like the above one? One of the versions could be as follows.
First, let's try to find an axiom, from which we could get A\IMPLIES A as a consequence.
By trying L1, i.e., B\IMPLIES (C\IMPLIES B), and setting B=C=A, we could obtain A\IMPLIES (A\IMPLIES A), a dead end, perhaps.
So, let's try L2, i.e., (B\IMPLIES (C\IMPLIES D))\IMPLIES ((B\IMPLIES C)\IMPLIES (B\IMPLIES D)).
By setting B=D=A we obtain (A\IMPLIES (C\IMPLIES A))\IMPLIES ((A\IMPLIES C)\IMPLIES (A\IMPLIES A)).
It seems to be a good decision --- because the first premise A\IMPLIES (C\IMPLIES A) is, in fact, L1.
Hence, by applying the MP rule, we obtain (A\IMPLIES C)\IMPLIES (A\IMPLIES A).
Now, how to make A\IMPLIES C ``provable''? Since C is, in fact, an arbitrary formula, we can replace C by C\IMPLIES A, obtaining (A\IMPLIES (C\IMPLIES A))\IMPLIES (A\IMPLIES A).
The premise is here, again, L1, hence, by applying the MP rule, we obtain A\IMPLIES A. Q.E.D.
By performing all our replacements at the very beginning, we obtain the above proof of the formula A\IMPLIES A.
[BTW, the above two smart ``operations'' --- obtaining A\IMPLIES A within L2, and making L1 of A\IMPLIES C, are applications of the so-called unification, a very general and very important method used in intellectual computer programs, for details, see Section 5.7.]

\begin{theorem}
%\label{}
Theorem 1.4.2. [L1, L2, MP]: \(A\IMPLIES B, B\IMPLIES C \vdash A\IMPLIES C\), for any formulas A, B, C. What does it mean? It's
the so-called Law of Syllogism (by Aristotle), or the transitivity property of implication.
\end{theorem}

The following sequence of formulas represents a proof of the formula A\IMPLIES C from the hypotheses A\IMPLIES B and B\IMPLIES C.

(1) A\IMPLIES B Hypothesis.

(2) B\IMPLIES C Hypothesis.

(3) (A\IMPLIES (B\IMPLIES C))\IMPLIES ((A\IMPLIES B)\IMPLIES (A\IMPLIES C)) It's the axiom schema L2: (B\IMPLIES (C\IMPLIES D))\IMPLIES ((B\IMPLIES C)\IMPLIES (B\IMPLIES D)), with B = A, C = B, D = C.

(4) (B\IMPLIES C)\IMPLIES (A\IMPLIES (B\IMPLIES C)) It's the axiom schema L1: B\IMPLIES (C\IMPLIES B), with B = B\IMPLIES C, C = A.

(5) A\IMPLIES (B\IMPLIES C) It follows from (2) and (4) by Modus Ponens.

(6) (A\IMPLIES B)\IMPLIES (A\IMPLIES C) It follows from (3) and (5) by Modus Ponens.

(7) A\IMPLIES C It follows from (1) and (6) by Modus Ponens.

\begin{note}
%\label{}
Only axiom schemas L1 and L2 , and inference rule Modus Ponens are used for proving the Theorems 1.4.1 and 1.4.2. Hence, these theorems will remain valid for any logical system containing L1, L2 and Modus Ponens.
\end{note}

\begin{exercise}
%\label{}
Exercise 1.4.1. Build sequences of formulas representing the following proofs (only the axiom schemas
L1 and L2 and Modus Ponens are necessary):
a) [L1, MP]: A \(\vdash\) B\IMPLIES A (a sequence of 3 formulas). What does it mean?
b) [L2, MP]: A\IMPLIES B, A\IMPLIES (B\IMPLIES C) \(\vdash\) A\IMPLIES C (a sequence of 5 formulas). What does it mean?
c) [L1, L2, MP]: A\IMPLIES (B\IMPLIES C) \(\vdash\) B\IMPLIES (A\IMPLIES C) (a sequence of 9 formulas --- thanks to Pavel Andreyev for the
idea). What does it mean? It's the so-called Premise Permutation Law.
d) [L1, L2, MP]: A\IMPLIES (A\IMPLIES B) \(\vdash\) A\IMPLIES B (a sequence of 9 formulas). What does it mean?
\end{exercise}

\begin{theorem}
%\label{}
[L14, MP, Gen] If F is any formula, and G is any formula that does not contain x as a free
variable, then
\[G\IMPLIES F(x) \vdash G\IMPLIES \forall xF(x).\]
\end{theorem}

The following sequence of formulas represents a proof of the formula G\IMPLIES \(\forall\) xF(x) from the hypothesis
G\IMPLIES F(x).

(1) G\IMPLIES F(x) Hypothesis.

(2) \(\forall\) x(G\IMPLIES F(x)) It follows from (1) by Generalization.

(3) \(\forall\) x(G\IMPLIES F(x))\IMPLIES (G\IMPLIES \(\forall\) xF(x)), It's the axiom schema L14 (G does not contain x as a free variable).

(4) G\IMPLIES \(\forall\) xF(x) It follows from (2) and (3) by Modus Ponens.

\begin{exercise}
%\label{}
Exercise 1.4.2. Build sequences of formulas representing the following proofs (F is any formula, and G is a formula that does not contain x as a free variable):

a) [L15, MP, Gen]: F(x)\IMPLIES G \(\vdash\) \(\exists\) xF(x)\IMPLIES G (a sequence of 4 formulas). What does it mean?

b) [L3-L5, MP]: A\AND B \(\vdash\) B\AND A (a sequence of 8 formulas). What does it mean?

c) [L6-L8, MP]: \(\vdash\) AvB\IMPLIES BvA (a sequence of 5 formulas). What does it mean?

d) [L1, L9, MP]: B, \(\neg B \vdash \neg C\) (a sequence of 9 formulas). What does it mean? It's 50\% of the axiom L10!

e) [L3, L4, L9, MP]: \(\vdash \neg (A\AND \neg A)\) (a sequence of 5 formulas). What does it mean? It's the so-called Law of Non-Contradiction.

f) [L1, L8, L10, MP]: \(\vdash \neg AvB\IMPLIES (A\IMPLIES B)\) (a sequence of 5 formulas). What does it mean?

g) [L8, L11, MP]: \(A\IMPLIES B, \neg A\IMPLIES B \vdash B\) (a sequence of 7 formulas). What does it mean?
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.4.3 (for smart students). Could one build shorter sequences proving Exercise 1.4.1 c), d) and
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.4.2 b), d)? Evgeny Vihrov verified in 2011 that any proof of Exercise 1.4.1 d) will be longer than 5 formulas.
\end{exercise}

\subsection{Deduction Theorems}

If, by assuming B as a hypothesis, we have proved C, then we have proved that B implies C. This trivial way of reasoning is formalized in the so-called deduction theorems (introduced by Jacques Herbrand and Alfred Tarski):

J. Herbrand. Recherches sur la th\'{e}orie de la d\'{e}monstration. PhD Thesis, University of Paris, 1930 (approved in April 1929).

A. Tarski. Ueber einige fundamentale Begriffe der Metamathematik. "Comptes Rendus de Séances de la Société des Sciences et des Lettres de Varsovie, Classe III", 1930, Vol.23, pp. 22-29.

We will prove two such theorems.

\begin{theorem}[Deduction Theorem 1]
%\label{}
If \(T\) is a first-order theory, and there is a proof \([T, MP]: \derive{A_1,A_2,\ldots,A_n,B}{C}\), then there is a proof \([L1, L2, T, MP]: \derive{A_1,A_2,\ldots,A_n}{B\IMPLIES C}\).
(In other words, having a Modus Ponens proof of \(C\) from the hypotheses \(A_1,A_2,\ldots,A_n,B\), we can build a Modus Ponens proof of \(B\IMPLIES C\) from the hypotheses \(A_1,A_2,\ldots,A_n\).)
\end{theorem}

It appears that, usually, proving of [T, MP]: \ldots  B \(\vdash\) C is easier (technically simpler) than proving of [T, MP]: \ldots  \(\vdash\) B\IMPLIES C.

\begin{exercise}[\(*\)]
%\label{}
Exercise 1.5.1. (For smart students) Do not read the proof below. Try proving yourself.
\end{exercise}

\begin{proof}
Proof (thanks to Sergey Kozlovich for the idea, see also Kleene [1967], Exercise 10C).
We must define a procedure allowing to convert any proof [T, MP]: A1, A2, \ldots , An, B \(\vdash\) C into a proof [L1, L2, T, MP]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
The easy way to do this would be using an induction by the number of formulas in the proof [T, MP]: A1, A2, \ldots , An, B \(\vdash\) C.
But we will use a more elegant idea.
Any proof of [T, MP]: A1, A2, \ldots , An, B \(\vdash\) C is a sequence of formulas F1, F2, \ldots Fm.
We will replace each formula Fi by 3 or 5 formulas, the last of these being the formula B\IMPLIES Fi, retaining our sequence as a valid proof.
We must consider the following cases:

1) F is an axiom (i.e., an instance of a logical axiom or a non-logical axiom of T).
Replace F by 3 formulas: F, F\IMPLIES (B\IMPLIES F), B\IMPLIES F.
The second formula is an instance of L1, the third formula is obtained from the first two ones by using Modus Ponens.

2) F is one of the hypotheses Ai.
Replace F by 3 formulas: F, F\IMPLIES (B\IMPLIES F), B\IMPLIES F.
The second formula is an instance of L1, the third formula is obtained from the first two ones by using Modus Ponens.

3) F is B.
Replace F by the 5 formulas from the proof of Theorem 1.4.1, where D is any formula: (B\IMPLIES ((D\IMPLIES B)\IMPLIES B))\IMPLIES ((B\IMPLIES (D\IMPLIES B))\IMPLIES (B\IMPLIES B)) (an instance of L2), B\IMPLIES ((D\IMPLIES B)\IMPLIES B) (an instance of L1), B\IMPLIES (D\IMPLIES B))\IMPLIES (B\IMPLIES B) (by Modus Ponens), B\IMPLIES (D\IMPLIES B) (an instance of L1,), B\IMPLIES B (by Modus Ponens).
The last formula is here, of course, B\IMPLIES F.

4) F is derived from some previous formulas Fi and Fj by Modus Ponens, Fi having the form Fj\IMPLIES F (i.e., Fj\IMPLIES F and Fj yield F by Modus Ponens).
Then, the formulas B\IMPLIES Fj, B\IMPLIES (Fj\IMPLIES F) are already present in the converted proof (they appeared during the replacement operations applied to the formulas Fj and Fj\IMPLIES F).
So, replace F by 3 formulas: (B\IMPLIES (Fj\IMPLIES F))\IMPLIES ((B\IMPLIES Fj)\IMPLIES (B\IMPLIES F)) (an instance of L2), (B\IMPLIES Fj)\IMPLIES (B\IMPLIES F) (by Modus Ponens), B\IMPLIES F (by Modus Ponens).

Thus, what we have now, is a correct proof in [L1, L2, MP] that is using the hypotheses A1, A2, \ldots , An, but not B! The last formula of this proof is B\IMPLIES C (because C is the last formula of our initial proof [L1, L2, MP]: A1, A2, \ldots , An, B \(\vdash\) C).
Thus, we have a proof [L1, L2, MP]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C. Q.E.D.
\end{proof}

The above proof of Deduction Theorem 1 includes, in fact, an algorithm allowing to obtain a proof of
[L1, L2, MP]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C from a given proof of [L1, L2, MP]: A1, A2, \ldots , An, B \(\vdash\) C. The
resulting proof is longer than the given one: if the given proof consists of m formulas, then the resulting
proof consists of 3m+2 formulas).

\begin{corollary}
%\label{}

Corollaries 1.5.1. 1) If there is a proof [T, MP]: A1, A2, \ldots , An, B1, B2, \ldots , Bk \(\vdash\) C , then there is a proof [L1, L2, T, MP]: A1, A2, \ldots , An \(\vdash\) (B1\IMPLIES (B2\IMPLIES (\ldots \IMPLIES (Bk\IMPLIES C)\ldots ))).
\end{corollary}

\begin{proof}
Proof. 1) By iterating the Deduction Theorem 1.
\end{proof}

\begin{corollary}
%\label{}
2) If T includes (or proves) schemas L1, L2, then, if there is a proof [T, MP]: A1, A2, \ldots , An, B \(\vdash\) C then
there is a proof [T, MP]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C .
In particular, if [T, MP ]: B \(\vdash\) C, then [T, MP]: \(\vdash\) B\IMPLIES C.
And, if [T, MP ]: B, C\(\vdash\) D, then [T, MP]: \(\vdash\) B\IMPLIES (C\IMPLIES D).
\end{corollary}

\begin{proof}
2) If T is a theory which includes or proves the schemas L1, L2, then [L1, L2, T, MP] is equivalent to [T, MP]. Q.E.D.
\end{proof}

\begin{exercise}
%\label{}
Exercise 1.5.2. In earlier versions of logical axioms, instead of the axiom L2, the following 3 axioms
were in use:
L21: (A\IMPLIES (A\IMPLIES B))\IMPLIES (A\IMPLIES B),
L22: (A\IMPLIES (B\IMPLIES C))\IMPLIES (B\IMPLIES (A\IMPLIES C)) (i.e., the Premise Permutation Law),
L23: (A\IMPLIES B)\IMPLIES ((B\IMPLIES C)\IMPLIES (A\IMPLIES C)) (the Law of Syllogism, or the transitivity property of implication).
Verify that both versions, i.e., [L1, L2, MP] and [L1, L21, L23, L23, MP] are equivalent. (Hint: a) See
Section 2.1 to verify that [L1, L2, MP] proves L21, L23, L23. b) Verify that [L1, L21, L23, L23, MP] proves
L2 either directly, or by proving the Deduction Theorem 1 for [L1, L21, L23, L23, MP].)
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.5.3 (thanks to Sergey Kozlovich for the idea).
a) Prove the following ``generalization'' of the Modus Ponens rule:
[L1, L2, MP]: (D1\IMPLIES (D2\IMPLIES \ldots (Dk\IMPLIES B)\ldots ), (D1\IMPLIES (D2\IMPLIES \ldots (Dk\IMPLIES (B\IMPLIES C))\ldots ) \(\vdash\) (D1\IMPLIES (D2\IMPLIES \ldots (Dk\IMPLIES C)\ldots ).
b) Prove the following ``generalization'' of the axiom L14 (formulas D1, D2, \ldots , Dk do not contain x as a
free variable):
[L1, L2, L14, MP]: \(\vdash \forall x(D1\IMPLIES (D2\IMPLIES \ldots (Dk\IMPLIES F(x))\ldots ) \IMPLIES  (D1\IMPLIES (D2\IMPLIES \ldots (Dk\IMPLIES \forall xF(x))\ldots ).\)
\end{exercise}

\begin{exercise}
%\label{}
Exercise 1.5.4. (For smart students) Investigate the size (the number of formulas) of the proof [L1, L2,
MP]: A1, A2, \ldots , An, \(\vdash B\IMPLIES C as a function f(m) of the size m of the proof [L1, L2, MP]: A1, A2, \ldots , An, B \vdash\)
C. You may wish to report your result. We will publish your report on the web as an appendix to this
book. The current record holder is Sergey Kozlovich, 2004: \(f(m) \leq 3m+2\). Improve this result, or prove
that it is the best one possible.
Exercise 1.5.5. (For smart students) Investigate the size (the number of instances of atomic formulas) of
the proof [L1, L2, MP]: A1, A2, \ldots , An, \(\vdash\) B\IMPLIES C as a function g(m) of the size m of the proof [L1, L2, MP]:
A1, A2, \ldots , An, B \(\vdash\) C. You may wish to report your result. We will publish your report on the web as an
appendix to this book. The current record holder is Kirils Solovjovs, 2008: \(g(m, n) \leq 7m+24n\)---2, where n
is the number of instances of atomic formulas in the formula B. Improve this result, or prove that it is the
best one possible.
\end{exercise}

Warning! Generalization involved\ldots 

Now, what, if in the proof of A1, A2, \ldots , An, B \(\vdash\) C not only Modus Ponens, yet also Generalization is used?  We must be careful, because, trying ``simply'' to apply Deduction Theorem 1, we can obtain crazy results.  Indeed, having a formula F(x), by Generalization, we obtain the formula \(\forall xF(x). Thus, F(x) \vdash \forall xF(x)\). If Deduction Theorem 1 could be extended to Gen without any restrictions, then we could conclude that \(\vdash\) F(x)\IMPLIES \(\forall\) xF(x). If this is true for any \(x\), it is true also for \(x=2\), hence, \(\vdash\) F(2)\IMPLIES \(\forall\) xF(x). Thus, if the number 2 is prime, then all numbers are prime?

So, let us try deriving a restricted formulation of the Deduction Theorem --- it seems, we should prohibit
application of Gen to free variables of B --- the hypothesis ``to be moved''.

\begin{theorem}
%\label{}
Theorem 1.5.2 (Deduction Theorem 2). If T is a first-order theory, and there is a proof [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C, where Generalization is not applied to free variables of B, then there is a proof [L1, L2, L14, T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
\end{theorem}

\begin{proof}
Proof. We must extend the above proof of the Deduction Theorem 1 that consisted of 4 cases. First, we
must extend the first case:
1') F is an axiom (i.e., an instance of a logical axiom or a non-logical axiom of T). Replace F by 3
formulas: F, F\IMPLIES (B\IMPLIES F), B\IMPLIES F. The second formula is an instance of L1, the third formula is obtained
from the first two ones by using Modus Ponens.
And we must add the following case:
5) F is derived from some previous formula Fi by Generalization, thus, F having the form \(\forall\) xFi, where x
is not free in the formula B. Replace F by the following 3 formulas:
\(\forall x(B\IMPLIES Fi)\IMPLIES (B\IMPLIES \forall xFi),\)
\(\forall x(B\IMPLIES Fi),\)
\(B\IMPLIES \forall xFi.\)
Since x is not free in B, the first formula is an instance of L14. The second formula is obtained by
Generalization from the formula B\IMPLIES Fi that is already present in the converted proof (it appeared during
the replacement operation applied to the formula Fi). The third formula is obtained from the first two ones
by using Modus Ponens.
Thus, what we have now, is a correct proof in [L1, L2, L14, MP, Gen] that is using the hypotheses A1,
A2, \ldots , An, but not B! The last formula of this proof is B\IMPLIES C (because C is the last formula our initial
proof [L1, L2, L14, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C). Thus, we have a proof [L1, L2, L14, MP, Gen]: A1,
A2, \ldots , An \(\vdash\) B\IMPLIES C. Q.E.D.
\end{proof}

\begin{corollary}
%\label{}

(1) If there is a proof [T, MP, Gen]: A1, A2, \ldots , An, B1, B2, \ldots , Bk \(\vdash\) C, where
Generalization is not applied to the free variables of the formulas B1, B2, \ldots , Bk, then there is a proof [L1,
L2, L14, T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) (B1\IMPLIES (B2\IMPLIES (\ldots \IMPLIES (Bk\IMPLIES C)\ldots ))).
\end{corollary}

\begin{corollary}
%\label{}

(2) If B is a closed formula, and there is a proof of [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C, then there is a
proof of [L1, L2, L14, T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
\end{corollary}

\begin{corollary}
%\label{}
(3) If T is a theory whose axioms include the schemas L1, L2, L14, then, if there is a proof [T, MP, Gen]:
A1, A2, \ldots , An, B \(\vdash\) C, where Generalization is not applied to the free variables of B, then there is a proof
[T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C. In particular, if [T, MP, Gen]: B \(\vdash\) C, where Generalization is not
applied to the free variables of B, then [T, MP, Gen]: \(\vdash\) B\IMPLIES C.
\end{corollary}

\begin{proof}
Proof. Similar to the proof of the above Corollaries of Deduction Theorem 1.
\end{proof}

Warning! Previously proved theorems involved\ldots 

In the real mathematical practice, when proving [T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) C we may wish to apply some theorem Q that we have already proved earlier. If we would simply insert Q into our formal proof, then, formally, this would yield only that [T, MP, Gen]: A1, A2, \ldots , An, Q \(\vdash\) C. To obtain the desired formal proof [T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) C, we must insert not only Q itself, but the entire proof of Q!

Still, with the Deduction Theorem 2 this may be problematic. If we are proving [T, MP, Gen]: A1, A2, \ldots ,
An, B \(\vdash\) C with the intention to apply Deduction Theorem 2 (to obtain [T, MP, Gen]: A1, A2, \ldots , An \(\vdash\)
B\IMPLIES C), then, before inserting the proof of Q, we must ensure that, in this proof, Generalization is not
applied to free variables of B. But, of course, the original proof of Q could contain such Generalizations!
To solve this problem, we could try, in the proof of Q, before inserting, rename simultaneously all the
variables to which Generalization is applied and which are free variables in B. But this simultaneous
renaming may affect the bound variables of Q, and thus --- destroy the intended use of Q\ldots 
The problem is solved completely by the following extension of the Deduction Theorem 2:
Theorem 1.5.3 (Deduction Theorem 2A). If there is a proof [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C, where,
after B appears in the proof, Generalization is not applied to free variables of B, then there is a proof
[L1, L2, L14, T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
Indeed, having such a theorem, we obtain the necessary

\begin{corollary}
%\label{}
If there is a proof [T, MP, Gen]: A1, A2, \ldots , An, B, Q \(\vdash\) C, where, after B appears in the
proof, Generalization is not applied to free variables of B, and there is a proof [T, MP, Gen]: A1, A2, \ldots ,
An \(\vdash\) Q, then there is a proof [T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
\end{corollary}

\begin{proof}
In the proof [T, MP, Gen]: A1, A2, \ldots , An, B, Q \(\vdash\) C, first, move the hypotheses A1, A2, \ldots , An to the
beginning. Then, immediately after them, insert the proof [T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) Q. Now we have
a proof [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C, where, after B appears in the proof, Generalization is not
applied to the free variables of B. By Deduction Theorem 2A, then there is a proof [T, MP, Gen]: A1,
A2, \ldots , An \(\vdash\) B\IMPLIES C. Q.E.D.
\end{proof}

\begin{proof}
Proof of the Deduction Theorem 2A. Let us modify the above proof of the Deduction Theorem 2.
We must define a procedure allowing to convert any allowed proof [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C
into a proof [L1, L2, T, MP, Gen]: A1, A2, \ldots , An \(\vdash\) B\IMPLIES C.
Unlike the above proof, let us leave unchanged all the formulas of the proof [T, MP]: A1, A2, \ldots , An, B \(\vdash\)
C before B appears in the proof. After this, starting with B, we will replace each formula F by 3 or 5
formulas, one of them being the formula B\IMPLIES F.
We must consider the following cases:
1), 2), 3) --- as in the proof of the Deduction Theorem 1.
4) F is derived from some previous formulas Fi and Fj by Modus Ponens, Fi having the form Fj\IMPLIES F (i.e.,
Fj\IMPLIES F and Fj yield F by Modus Ponens). Then, 4 subcases are possible.
4a) Fj and Fj\IMPLIES F both appear before B, i.e., they remain unchanged in the converted proof. Let us replace
F by the following 3 formulas: F, F\IMPLIES (B\IMPLIES F), B\IMPLIES F. The second formula is an instance of L1, the third
formula is obtained by using Modus Ponens from the first two ones.
4b) Fj appears before B, and Fj\IMPLIES F is B or appears after B. Then, the formulas Fj and B\IMPLIES (Fj\IMPLIES F) are
already present in the converted proof. Let us replace F by the following 5 formulas:
(B\IMPLIES (Fj\IMPLIES F))\IMPLIES ((B\IMPLIES Fj)\IMPLIES (B\IMPLIES F)) (an instance of L2),
(B\IMPLIES Fj)\IMPLIES (B\IMPLIES F) (by Modus Ponens),
Fj\IMPLIES (B\IMPLIES Fj) (an instance of L1),
B\IMPLIES Fj (by Modus Ponens),
B\IMPLIES F (by Modus Ponens).
4c) Fj is B or appears after B, and Fj\IMPLIES F appears before B. Then, the formulas B\IMPLIES Fj and Fj\IMPLIES F are
already present in the converted proof. Let us replace F by the following 5 formulas from the proof of
Theorem 1.4.2:
(B\IMPLIES (Fj\IMPLIES F))\IMPLIES ((B\IMPLIES Fj)\IMPLIES (B\IMPLIES F)) (an instance of L2),
(Fj\IMPLIES F)\IMPLIES (B\IMPLIES (Fj\IMPLIES F)) (an instance of L1),
B\IMPLIES (Fj\IMPLIES F) (by Modus Ponens),
(B\IMPLIES Fj)\IMPLIES (B\IMPLIES F) (by Modus Ponens),
B\IMPLIES F (by Modus Ponens).
(4d) Fj and Fj\IMPLIES F both are B or appear after B. Then, the formulas B\IMPLIES Fj and B\IMPLIES (Fj\IMPLIES F) are already
present in the converted proof (they appeared during the replacement operations applied to the formulas
Fj and Fj\IMPLIES F). Let us replace F by the following 3 formulas:
(B\IMPLIES (Fj\IMPLIES F))\IMPLIES ((B\IMPLIES Fj)\IMPLIES (B\IMPLIES F)) (an instance of L2),
(B\IMPLIES Fj)\IMPLIES (B\IMPLIES F) (by Modus Ponens),
B\IMPLIES F (by Modus Ponens).
(5) F is derived from some previous formula Fi by Generalization, thus, F having the form \(\forall\) xFi. Then, 2
subcases are possible.
(5a) Fi appears before B. Then x is not free in B. Let us replace F by the following 3 formulas:
F (by Generalization, x is not free in B),
F\IMPLIES (B\IMPLIES F) (an instance of L1),
B\IMPLIES F
(5b) Fi is B or appears after B. Then x is not free in B, and the formula B\IMPLIES Fi that is already present in the
converted proof (it appeared during the replacement operation applied to the formula Fi). Let us replace F
by the following 3 formulas:
\(\forall x(B\IMPLIES Fi)\) (by Generalization, x is not free in B),
\(\forall x(B\IMPLIES Fi)\IMPLIES (B\IMPLIES \forall xFi)\) (an instance of L14, since x is not free in B),
\(B\IMPLIES \forall xFi\) (by Modus Ponens).

Thus, what we have now, is a correct proof in [L1, L2, L14, T, MP, Gen] that is using the hypotheses A1,
A2, \ldots , An, but not B! The last formula of this proof is B\IMPLIES C (because C is the last formula our initial
proof [T, MP, Gen]: A1, A2, \ldots , An, B \(\vdash\) C). Thus, we have a proof [L1, L2, L14, T, MP, Gen]: A1, A2, \ldots ,
An \(\vdash\) B\IMPLIES C. Q.E.D.
\end{proof}

\begin{exercise}
In some other textbooks, a somewhat different system of logical axioms is used: instead of the axioms \(L_{14}\), \(L_{15}\) and the Generalization rule the following two rules of inference are used:
\begin{itemize}
    \item \(G\IMPLIES F(x) \vdash G\IMPLIES \forall xF(x)\) (\(\forall\)-Introduction),
    \item \(F(x)\IMPLIES G \vdash \exists xF(x)\IMPLIES G\) (\(\exists\)-Elimination).
\end{itemize}
Of course, here, \(G\) is a formula that does not contain \(x\) as a free variable. Verify that both systems are
equivalent in all of their versions (minimal, constructive, and classical).
\end{exercise}
